#!/bin/bash

#####
# esg-node: ESG Data Node Application Stack
# chkconfig: 345 98 02
# description: Installer for the ESG Data Node application stack
#
#****************************************************************************
#*                                                                          *
#*  Organization: Lawrence Livermore National Lab (LLNL)                    *
#*   Directorate: Computation                                               *
#*    Department: Computing Applications and Research                       *
#*      Division: S&T Global Security                                       *
#*        Matrix: Atmospheric, Earth and Energy Division                    *
#*       Program: PCMDI                                                     *
#*       Project: Earth Systems Grid (ESG) Data Node Software Stack         *
#*  First Author: Gavin M. Bell (gavin@llnl.gov)                            *
#*                                                                          *
#****************************************************************************
#*                                                                          *
#*   Copyright (c) 2009, Lawrence Livermore National Security, LLC.         *
#*   Produced at the Lawrence Livermore National Laboratory                 *
#*   Written by: Gavin M. Bell (gavin@llnl.gov)                             *
#*   LLNL-CODE-420962                                                       *
#*                                                                          *
#*   All rights reserved. This file is part of the:                         *
#*   Earth System Grid (ESG) Data Node Software Stack, Version 1.0          *
#*                                                                          *
#*   For details, see http://esg-repo.llnl.gov/esg-node/                    *
#*   Please also read this link                                             *
#*    http://esg-repo.llnl.gov/LICENSE                                      *
#*                                                                          *
#*   * Redistribution and use in source and binary forms, with or           *
#*   without modification, are permitted provided that the following        *
#*   conditions are met:                                                    *
#*                                                                          *
#*   * Redistributions of source code must retain the above copyright       *
#*   notice, this list of conditions and the disclaimer below.              *
#*                                                                          *
#*   * Redistributions in binary form must reproduce the above copyright    *
#*   notice, this list of conditions and the disclaimer (as noted below)    *
#*   in the documentation and/or other materials provided with the          *
#*   distribution.                                                          *
#*                                                                          *
#*   Neither the name of the LLNS/LLNL nor the names of its contributors    *
#*   may be used to endorse or promote products derived from this           *
#*   software without specific prior written permission.                    *
#*                                                                          *
#*   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS    *
#*   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT      *
#*   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS      *
#*   FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL LAWRENCE    *
#*   LIVERMORE NATIONAL SECURITY, LLC, THE U.S. DEPARTMENT OF ENERGY OR     *
#*   CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,           *
#*   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT       *
#*   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF       *
#*   USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND    *
#*   ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,     *
#*   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT     *
#*   OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF     *
#*   SUCH DAMAGE.                                                           *
#*                                                                          *
#****************************************************************************
#####

#uses: perl, awk, ifconfig, tar, wget, curl, su, useradd, groupadd,
#      id, chmod, chown, chgrp, cut, svn, mkdir, killall, java, egrep,
#      lsof, unlink, ln

#note: usage of readlink not macosx friendly :-( usage of useradd /
#      groupadd is RedHat/CentOS dependent :-(

DEBUG=${DEBUG:-0}

#--------------
#User Defined / Settable (public)
#--------------
progname=esg-node
version="0.3.1"

envfile=${envfile:-"/etc/esg.env"}
t=${0%.*}
logfile=${logfile:-"/var/tmp/${t##*/}.out"}
install_prefix=${install_prefix:-"/usr/local"}
workdir=${workdir:-~/workbench/esg}

init() {
    [ -e ${envfile} ] && source ${envfile} && printf "sourcing environment from: ${envfile} \n\n"

    #internal data-node code versions
    cdat_version=${cdat_version:-"095acf5"}
    esgcet_version=${esgcet_version:-"2.3"}
    node_version=${node_version:-".0.0.2"}
    
    #external programs' versions
    curl_version=${curl_version:="7.20.1"}
    git_version=${git_version:="1.7.1"}
    java_version=${java_version:-"1.6.0_20"}
    ant_version=${ant_version:-"1.8.1"}
    postgress_version=${postgress_version:-"8.4.3"}
    tomcat_version=${tomcat_version:-"6.0.26"}
    tds_version=${tds_version:-"4.1"}

    install_logfile=${ESG_INSTALL_LOGFILE:-"/etc/esg.install_log"}
    curl_install_dir=${CURL_HOME:-${install_prefix}/curl}
    git_install_dir=${GIT_HOME:-${install_prefix}/git}
    postgress_install_dir=${PGHOME:-${install_prefix}/pgsql}
    postgress_user=${PGUSER:-dbsuper}
    pg_sys_acct_passwd=${pg_sys_acct_passwd:=changeme}
    postgress_host=${PGHOST:-localhost}
    postgress_port=${PGPORT:-5432}
    cdat_home=${CDAT_HOME:-${install_prefix}/cdat}
    java_opts=${JAVA_OPTS:-"-Xmx2048m -Xms1024m"}
    java_install_dir=${JAVA_HOME:-${install_prefix}/java}
    ant_install_dir=${ANT_HOME:-${install_prefix}/ant}
    tomcat_install_dir=${CATALINA_HOME:-${install_prefix}/tomcat}
    tomcat_user=${tomcat_user:-tomcat}
    tomcat_group=${tomcat_group:-$tomcat_user}
    globus_location=${GLOBUS_LOCATION:-${install_prefix}/globus}
    backupdir=${backupdir:-"/esg/backups"}
    gateway_name=${ESG_GATEWAY_NAME}
    gateway_service_root=${ESG_GATEWAY_SVC_ROOT}
    myproxy_endpoint=${myproxy_endpoint:-${gateway_service_root%%/*}}
    myproxy_port=${myproxy_port:-7512}
    esg_root_id=${ESG_ROOT_ID:-$(echo `hostname -s`.`hostname --domain` | awk -F. ' {print $(NF-1)} ')}
    mail_smtp_host=${mail_smtp_host:-smtp.`hostname --domain`} #standard guess.
    mail_admin_address=${mail_admin_address}
    gridftp_config_args=${gridftp_config_args:-""}
    
    ############################################
    ####  DO NOT EDIT BELOW THIS POINT!!!!! ####
    ############################################
    
    export CURL_HOME=${curl_install_dir}
    export GIT_HOME=${git_install_dir}
    export PGHOME=${postgress_install_dir}
    export PGUSER=${postgress_user}
    export PGHOST=${postgress_host}
    export PGPORT=${postgress_port}
    export CDAT_HOME=${cdat_home}
    export JAVA_HOME=${java_install_dir}
    export JAVA_OPTS=${java_opts}
    export ANT_HOME=${ant_install_dir}
    export CATALINA_HOME=${tomcat_install_dir}
    export CATALINA_BASE=${CATALINA_HOME}
    export GLOBUS_LOCATION=${globus_location}
    export X509_CERT_DIR=${HOME}/.globus/certificates-esg
    export ESG_ROOT_ID=${esg_root_id}
    
    myPATH=$CURL_HOME/bin:$GIT_HOME/bin:$JAVA_HOME/bin:$ANT_HOME/bin:$PGHOME/bin:$CDAT_HOME/bin:$CDAT_HOME/Externals/bin:$CATALINA_HOME/bin:$GLOBUS_LOCATION/bin:/bin:/sbin:/usr/bin
    myLD_LIBRARY_PATH=$CURL_HOME/lib:$PGHOME/lib:$CDAT_HOME/Externals/lib:$GLOBUS_LOCATION/lib
    export PATH=$myPATH:$PATH
    export LD_LIBRARY_PATH=$myLD_LIBRARY_PATH:$LD_LIBRARY_PATH
    
    
    
    #--------------
    #Script vars (internal)
    #--------------
    word_size=${word_size:-$(file /bin/bash | perl -ple 's/^.*ELF\s*(32|64)-bit.*$/$1/g')}
    esg_dist_url=http://rainbow.llnl.gov/dist
    date_format="+%Y_%m_%d_%H%M%S"
    num_backups_to_keep=${num_backups_to_keep:-7}
    java_dist_url=${esg_dist_url}/java/${java_version}/jdk${java_version}-${word_size}.tar.gz
    ant_dist_url=http://www.trieuvan.com/apache/ant/binaries/apache-ant-${ant_version}-bin.tar.gz
    curl_workdir=${workdir}/curl
    curl_dist_url=http://curl.haxx.se/download/curl-${curl_version}.tar.gz
    git_workdir=${workdir}/git
    git_dist_url=http://kernel.org/pub/software/scm/git/git-${git_version}.tar.gz
    postgress_workdir=${workdir}/postgress
    postgress_jar=postgresql-8.3-603.jdbc3.jar
    postgress_driver=org.postgresql.Driver
    postgress_protocol=jdbc:postgresql:
    pg_sys_acct=${pg_sys_acct:-postgres}
    pg_sys_acct_group=${pg_sys_acct_group:-$pg_sys_acct}
    postgress_dist_url=http://ftp9.us.postgresql.org/pub/mirrors/postgresql/source/v${postgress_version}/postgresql-${postgress_version}.tar.gz
    cdat_repo=http://esg-repo.llnl.gov/git/cdat.git
    esgcet_egg_file=esgcet-${esgcet_version}-py2.5.egg
    esg_testdir=${workdir}/../esg_test
    tomcat_dist_url=http://download.filehat.com/apache/tomcat/tomcat-6/v${tomcat_version}/bin/apache-tomcat-${tomcat_version}.tar.gz
    tomcat_pid_file=/var/run/tomcat-jsvc.pid
    utils_url=${esg_dist_url}/utils
    thredds_dist_url=ftp://ftp.unidata.ucar.edu/pub/thredds/${tds_version}/thredds.war
    thredds_esg_dist_url=${esg_dist_url}/thredds/${tds_version}/thredds.war
    #NOTE: This root dir should match a root set in the thredds setup 
    thredds_root_dir=/esg/data
    thredds_replica_dir=/esg/data.replica
    node_dist_url=${esg_dist_url}/esg-node/esg-node${node_version}.tar.gz
    node_db_name=esgcet
    node_app_context_root=esg-node
    node_app_home=${tomcat_install_dir}/webapps/${node_app_context_root}
    #NOTE: This is another RedHat/CentOS specific portion!!! it will break on another OS!
    my_ip_address=$(ifconfig | grep "inet[^6]" | awk '$0 !~ /127.0.0.1/ { gsub (" *inet [^:]*:",""); print $1}')
    show_summary_latch=0
    source_latch=0
    node_host_ip_address=${my_ip_address}
    scripts_dir=${install_prefix}/bin
    no_globus=${no_globus:-0}
    keystore_file=${tomcat_install_dir}/conf/keystore-tomcat
    keystore_alias=tomcat
    keystore_password=changeit
    truststore_file=${tomcat_install_dir}/conf/jssecacerts

    write_paths
}

write_paths() {
    ((show_summary_latch++))
    echo "export PATH=$myPATH:\$PATH" >> ${envfile}
    echo "export LD_LIBRARY_PATH=$myLD_LIBRARY_PATH:\$LD_LIBRARY_PATH" >> ${envfile}
    echo "export ESG_INSTALL_LOGFILE=${install_logfile}" >> ${envfile}
    dedup ${envfile}
}

#checking for what we expect to be on the system a-priori
#that we are not going to install or be responsible for
check_prerequisites() {
    printf "Checking that you are root@${my_ip_address}... " 
    id | grep root >& /dev/null
    [ $? != 0 ] && printf "[FAIL] \n\tMust run this program with root's effective UID\n\n" && return 1
    echo "[OK]"

    #----------------------------------------
    echo "Checking requisites... "

    echo -n "Checking for gmake... "
    gmake --version >& /dev/null
    [ $? != 0 ] && echo "[FAIL]" && return 1
    echo "[OK]"

    echo -n "Checking for X11 libs... "
    Xorg -version >& /dev/null 
    if [ $? != 0 ]; then
	echo "[WARNING] X11 is needed for publisher UI..."
    else
	echo "[OK]"
    fi
    #----------------------------------------
    echo
    return 0
}

#####
# Curl/libcurl (support library - needed to support HTTP protocol in GIT)
#####
setup_curl() {

    echo -n "Checking for curl ${curl_version} "
    check_version curl ${curl_version}
    [ $? == 0 ] && echo " [OK]" && return 0
    
    echo
    echo "*******************************"
    echo "Setting up Curl/Libcurl ${curl_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${curl_install_dir}/bin/curl ]; then 
	echo "Detected an existing (older) CURL installation..."
	read -p "Do you want to continue with CURL installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping CURL installation and setup - will assume CURL is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${curl_workdir}
    [ $? != 0 ] && checked_done 1
    chmod a+rw ${curl_workdir}
    pushd ${curl_workdir} >& /dev/null
    
    local curl_dist_file=${curl_dist_url##*/}
    #strip off .tar.gz at the end, i.e. last 7 chars, to get untarred dir name
    local curl_dist_dir=$(echo ${curl_dist_file} | awk '{print substr($1,1,length($1)-7)}')
        
    #There is this pesky case of having a zero sized dist file... WTF!?
    if [ -e ${curl_dist_file} ]; then
        ls -l ${curl_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${curl_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${curl_dist_file}
    fi

    #Check to see if we have postgres distribution directory
    if [ ! -e ${curl_dist_dir} ]; then
	echo "Don't see CURL distribution dir ${curl_dist_dir}"
	if [ ! -e ${curl_dist_file} ]; then
	    echo "Don't see CURL distribution file ${curl_dist_file} either"
	    echo "Downloading CURL from ${curl_dist_url}"
	    wget -O ${curl_dist_file} ${curl_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download CURL:${curl_dist_file}" && popd && checked_done 1
	    tar xvzf ${curl_dist_file}
	    [ $? != 0 ] && echo " ERROR: Could not extract CURL: ${curl_dist_file}" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it and go from there....
    if [ -e ${curl_dist_file} ] && [ ! -e ${curl_dist_dir} ]; then
	tar xvzf ${curl_dist_file}
    fi

    pushd ${curl_dist_dir}
    echo "./configure --prefix=${curl_install_dir}"
    if ./configure --prefix=${curl_install_dir} \
	&& gmake all \
	&& gmake install 
	then
	echo "Successfully Configured and Built CURL in: ${curl_install_dir}"
	#this is the "test"
	${curl_install_dir}/bin/curl --version
	[ $? != 0 ] && 	echo" ERROR: Could NOT successfully build CURL!!" && popd >& /dev/null && checked_done 1
    else
	echo" ERROR: Could NOT successfully build CURL!!"
	popd >& /dev/null
	checked_done 1
    fi

    popd >& /dev/null
    popd >& /dev/null

    write_curl_env
    write_curl_install_log
    checked_done 0
}

write_curl_env() {
    ((show_summary_latch++))
    echo "export CURL_HOME=${curl_install_dir}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_curl_install_log() {
    echo "$(date ${date_format}) curl=${curl_version} ${curl_install_dir}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}

#####
# GIT
#####
setup_git() {

    echo -n "Checking for git ${git_version}"
    check_version git ${git_version}
    [ $? == 0 ] && echo " [OK]" && return 0
    
    echo
    echo "*******************************"
    echo "Setting up GIT (dvcs) ${git_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${git_install_dir}/bin/git ]; then 
	echo "Detected an existing (older) GIT installation..."
	read -p "Do you want to continue with GIT installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping GIT installation and setup - will assume GIT is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${git_workdir}
    [ $? != 0 ] && checked_done 1
    chmod a+rw ${git_workdir}
    pushd ${git_workdir} >& /dev/null

    local git_dist_file=${git_dist_url##*/}
    #strip off .tar.gz at the end, i.e. last 7 chars, to get untarred dir name
    local git_dist_dir=$(echo ${git_dist_file} | awk '{print substr($1,1,length($1)-7)}')
        
    #There is this pesky case of having a zero sized dist file... WTF!?
    if [ -e ${git_dist_file} ]; then
        ls -l ${git_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${git_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${git_dist_file}
    fi

    #Check to see if we have postgres distribution directory
    if [ ! -e ${git_dist_dir} ]; then
	echo "Don't see GIT distribution dir ${git_dist_dir}"
	if [ ! -e ${git_dist_file} ]; then
	    echo "Don't see GIT distribution file ${git_dist_file} either"
	    echo "Downloading GIT from ${git_dist_url}"
	    wget -O ${git_dist_file} ${git_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download GIT:${git_dist_file}" && popd && checked_done 1
	    tar xvzf ${git_dist_file}
	    [ $? != 0 ] && echo " ERROR: Could not extract GIT: ${git_dist_file}" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it and go from there....
    if [ -e ${git_dist_file} ] && [ ! -e ${git_dist_dir} ]; then
	tar xvzf ${git_dist_file}
    fi

    pushd ${git_dist_dir}
    echo "./configure --prefix=${git_install_dir}"
    if ./configure --prefix=${git_install_dir} \
	&& gmake all \
	&& gmake install 
	then
	echo "Successfully Configured and Built GIT in: ${git_install_dir}"
	#this is the "test"
	${git_install_dir}/bin/git --version
	[ $? != 0 ] && 	echo" ERROR: Could NOT successfully build GIT!!" && popd >& /dev/null && checked_done 1
    else
	echo" ERROR: Could NOT successfully build GIT!!"
	popd >& /dev/null
	checked_done 1
    fi

    popd >& /dev/null
    popd >& /dev/null

    write_git_env
    write_git_install_log
    checked_done 0
}

write_git_env() {
    ((show_summary_latch++))
    echo "export GIT_HOME=${git_install_dir}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_git_install_log() {
    echo "$(date ${date_format}) git=${git_version} ${git_install_dir}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}

#####
# Java
#####
setup_java() {

    echo -n "Checking for java ${java_version} and valid JAVA_HOME... "
    [ -e ${java_install_dir} ] && check_version $java_install_dir/bin/java ${java_version}
    [ $? == 0 ] && echo " [OK]" && return 0

    echo
    echo "*******************************"
    echo "Setting up Java... ${java_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${java_install_dir}/bin/java ]; then 
	echo "Detected an existing (older) java installation..."
	read -p "Do you want to continue with Java installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping Java installation and setup - will assume Java is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} #>& /dev/null
    
    local java_dist_file=${java_dist_url##*/}
    #strip off -32.tar.gz at the end, i.e. last 10 chars, to get untarred dir name
    java_dist_dir=$(echo ${java_dist_file} | awk '{print substr($1,1,length($1)-10)}')

    #Check to see if we have an Java distribution directory
    if [ ! -e ${java_install_dir%/*}/${java_dist_dir} ]; then
	echo "Don't see java distribution dir ${java_install_dir%/*}/${java_dist_dir}"
	if [ ! -e ${java_dist_file} ]; then
	    echo "Don't see java distribution file $(pwd)/${java_dist_file} either"
	    echo "Downloading Java from ${java_dist_url}"
	    checked_get ${java_dist_file} ${java_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download Java" && popd && checked_done 1
    	    tar xvzf ${java_dist_file} -C ${java_install_dir%/*} # i.e. /usr/local
	    [ $? != 0 ] && echo " ERROR: Could not extract Java" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it
    if [ -e ${java_dist_file} ] && [ ! -e ${java_install_dir%/*}/${java_dist_dir} ]; then
	tar xvzf ${java_dist_file} -C ${java_install_dir%/*} # i.e. /usr/local
	[ $? != 0 ] && echo " ERROR: Could not extract Java..." && popd && checked_done 1
    fi

    if [ ! -e ${java_install_dir} ]; then
	ln -s ${java_install_dir%/*}/${java_dist_dir} ${java_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR: Could not create sym link ${java_install_dir%/*}/${java_dist_dir} -> ${java_install_dir}" && popd && checked_done 1
    else
	unlink ${java_install_dir} 
	[ $? != 0 ] && mv ${java_install_dir} ${java_install_dir}.$(date ${date_format}).bak
	
	ln -s ${java_install_dir%/*}/${java_dist_dir} ${java_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR*: Could not create sym link ${java_install_dir%/*}/${java_dist_dir} -> ${java_install_dir}" && popd && checked_done 1
    fi

    popd >& /dev/null

    ${java_install_dir}/bin/java -version
    [ $? != 0 ] && echo "ERROR cannot run ${java_install_dir}/bin/java" && checked_done 1
    write_java_env
    write_java_install_log
    checked_done 0
}

write_java_env() {
    ((show_summary_latch++))
    echo "export JAVA_HOME=${java_install_dir}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_java_install_log() {
    echo "$(date ${date_format}) java=${java_version} ${java_install_dir%/*}/${java_dist_dir}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}


#####
# Ant
#####
setup_ant() {

    echo -n "Checking for ant ${ant_version}"
    [ -e ${ant_install_dir} ] &&  check_version ${ant_install_dir}/bin/ant ${ant_version}
    [ $? == 0 ] && echo " [OK]" && return 0

    echo
    echo "*******************************"
    echo "Setting up Ant... ${ant_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${ant_install_dir}/bin/ant ]; then 
	echo "Detected an existing (older) ant installation..."
	read -p "Do you want to continue with Ant installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping Ant installation and setup - will assume ant is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null
    
    local ant_dist_file=${ant_dist_url##*/}
    #strip off -bin.tar.gz at the end, i.e. last 11 chars, to get untarred dir name
    ant_dist_dir=$(echo ${ant_dist_file} | awk '{print substr($1,1,length($1)-11)}')

    #There is this pesky case of having a zero sized dist file... WTF!?
    if [ -e ${ant_dist_file} ]; then
        ls -l ${ant_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${ant_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${ant_dist_file}
    fi

    #Check to see if we have an Ant distribution directory
    if [ ! -e ${ant_install_dir%/*}/${ant_dist_dir} ]; then
	echo "Don't see ant distribution dir ${ant_install_dir%/*}/${ant_dist_dir}"
	if [ ! -e ${ant_dist_file} ]; then
	    echo "Don't see ant distribution file $(pwd)/${ant_dist_file} either"
	    echo "Downloading Ant from ${ant_dist_url}"
	    wget -O ${ant_dist_file} ${ant_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download Ant" && popd && checked_done 1
    	    tar xvzf ${ant_dist_file} -C ${ant_install_dir%/*} # i.e. /usr/local
	    [ $? != 0 ] && echo " ERROR: Could not extract Ant" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it
    if [ -e ${ant_dist_file} ] && [ ! -e ${ant_install_dir%/*}/${ant_dist_dir} ]; then
	tar xvzf ${ant_dist_file} -C ${ant_install_dir%/*} # i.e. /usr/local
	[ $? != 0 ] && echo " ERROR: Could not extract Ant..." && popd && checked_done 1
    fi

    if [ ! -e ${ant_install_dir} ]; then
	ln -s ${ant_install_dir%/*}/${ant_dist_dir} ${ant_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR: Could not create sym link ${ant_install_dir%/*}/${ant_dist_dir} -> ${ant_install_dir}" && popd && checked_done 1
    else
	unlink ${ant_install_dir} 
	[ $? != 0 ] && mv ${ant_install_dir} ${ant_install_dir}.$(date ${date_format}).bak

	ln -s ${ant_install_dir%/*}/${ant_dist_dir} ${ant_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR: Could not create sym link ${ant_install_dir%/*}/${ant_dist_dir} -> ${ant_install_dir}" && popd && checked_done 1
    fi

    ${ant_install_dir}/bin/ant -version
    [ $? != 0 ] && echo "ERROR cannot run ${ant_install_dir}/bin/ant" && checked_done 1
    write_ant_env
    write_ant_install_log
    checked_done 0

}

write_ant_env() {
    ((show_summary_latch++))
    echo "export ANT_HOME=${ant_install_dir}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_ant_install_log() {
    echo "$(date ${date_format}) ant=${ant_version} $(readlink -f ${ant_install_dir})" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}

#####
# PostgreSQL
#####
setup_postgress() {

    echo -n "Checking for postgresql ${postgress_version}"
    check_version psql ${postgress_version}
    [ $? == 0 ] && echo " [OK]" && return 0

    echo
    echo "*******************************"
    echo "Setting up PostgreSQL... ${postgress_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${postgress_install_dir}/bin/psql ]; then 
	echo "Detected an existing (older) postgress installation..."
	read -p "Do you want to continue with postgress installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping postgres installation and setup - will assume postgres is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${postgress_workdir}
    [ $? != 0 ] && checked_done 1
    chmod a+rw ${postgress_workdir}
    pushd ${postgress_workdir} >& /dev/null

    local postgress_dist_file=${postgress_dist_url##*/}
    #strip off .tar.gz at the end, i.e. last 7 chars, to get untarred dir name
    postgress_dist_dir=$(echo ${postgress_dist_file} | awk '{print substr($1,1,length($1)-7)}')
        
    #There is this pesky case of having a zero sized dist file... WTF!?
    if [ -e ${postgress_dist_file} ]; then
        ls -l ${postgress_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${postgress_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${postgress_dist_file}
    fi

    #Check to see if we have postgres distribution directory
    if [ ! -e ${postgress_dist_dir} ]; then
	echo "Don't see postgress distribution dir ${postgress_dist_dir}"
	if [ ! -e ${postgress_dist_file} ]; then
	    echo "Don't see postgress distribution file ${postgress_dist_file} either"
	    echo "Downloading Postgress from ${postgress_dist_url}"
	    wget -O ${postgress_dist_file} ${postgress_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download Postgress:${postgress_dist_file}" && popd && checked_done 1
	    tar xvzf ${postgress_dist_file}
	    [ $? != 0 ] && echo " ERROR: Could not extract Postgress: ${postgress_dist_file}" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it and go from there....
    if [ -e ${postgress_dist_file} ] && [ ! -e ${postgress_dist_dir} ]; then
	tar xvzf ${postgress_dist_file}
    fi

    pushd ${postgress_dist_dir}
    echo "./configure --prefix=${postgress_install_dir} --enable-thread-safety"
    if ./configure --prefix=${postgress_install_dir} --enable-thread-safety \
	&& gmake \
	&& gmake install \
	&& cd contrib/tablefunc/ \
	&& gmake \
	&& gmake install
	then
	echo "Successfully Configured and Built PostgresSQL in: ${postgress_install_dir}"
    else
	echo" ERROR: Could NOT successfully build POSTGRESS!"
	popd >& /dev/null
	checked_done 1
    fi

    popd >& /dev/null
    
    ########
    #Create the system account for postgress to run as.
    ########
    id $pg_sys_acct
    if [ $? != 0 ]; then
	echo " WARNING: There is no postgres system account user \"$pg_sys_acct\" present on system"
	#NOTE: "useradd/groupadd" are a RedHat/CentOS thing... to make this cross distro compatible clean this up.
	/usr/sbin/groupadd -r -f ${pg_sys_acct_group}
	[ $? != 0 ] && echo "ERROR: Could not add postgres system group: ${pg_sys_acct_group}" && popd && checked_done 1
	/usr/sbin/useradd -r -u26 -c"PostgreSQL Service" -g $pg_sys_acct_group -p $pg_sys_acct_passwd $pg_sys_acct
	[ $? != 0 ] && echo "ERROR: Could not add postgres system account user" && popd && checked_done 1
    fi
    ########
    sleep 3
    #double check that the account is really there!
    echo
    id $pg_sys_acct >& /dev/null
    [ $? != 0 ] && grep $pg_sys_acct /etc/passwd && echo " ERROR: Problem with $pg_sys_acct creation!!!" && checked_done 1

    chown -R $pg_sys_acct $postgress_install_dir
    chgrp -R $pg_sys_acct_group $postgress_install_dir


    #Create the database:
    mkdir -p ${postgress_install_dir}/data
    chown -R ${pg_sys_acct} ${postgress_install_dir}/data
    [ $? != 0 ] && " ERROR: Could not change ownership of postgres' data to \"$pg_sys_acct\" user" && popd && checked_done 1

    chmod 700 $postgress_install_dir/data
    su $pg_sys_acct -c "$postgress_install_dir/bin/initdb -D $postgress_install_dir/data"
    mkdir $postgress_install_dir/log
    chown -R $pg_sys_acct $postgress_install_dir/log
    [ $? != 0 ] && " ERROR: Could not change ownership of postress' log to \"$pg_sys_acct\" user" && popd && checked_done 1


    #Start the database 
    start_postgress

    echo "$postgress_install_dir/bin/createuser -U $pg_sys_acct -P -s -e $postgress_user"
    $postgress_install_dir/bin/createuser -U $pg_sys_acct -P -s -e $postgress_user
    [ $? != 0 ] && echo " ERROR: Unable to create user on the system" && popd && checked_done 1

    #stop_postgress && return 1 #See trap in 'main'... that is who calls this.
    
    local fetch_file

    cd $postgress_install_dir/data
    #Get files
    fetch_file=pg_hba.conf
    checked_get ./${fetch_file} ${esg_dist_url}/externals/bootstrap/${fetch_file}
    (( $? > 1 )) && popd && checked_done 1
    chmod 600 ${fetch_file}


    #Get File...
    fetch_file=postgresql.conf
    checked_get ./${fetch_file} ${esg_dist_url}/externals/bootstrap/${fetch_file}
    (( $? > 1 )) && popd && checked_done 1
    chmod 600 ${fetch_file}

    #-----
    #NOTE: This database is an internal database to this esg
    #application stack... I don't think it would even be prudent to
    #offer then opportunity for someone to bind to the public
    #interface.  If they choose to do so after the fact, then they are
    #making that conscious decision, but I won't make it a part of
    #this process.

    #@@postgress_host@@ #Token in file...

    #local input
    #read -p "Please Enter the IP address or name of this host [${postgress_host}]:> " input
    #[ ! -z "${input}" ] && postgress_host=${input}
    #printf "\nUsing IP: ${postgress_host}\n"
    #eval "perl -p -i -e 's/\\@\\@postgress_host\\@\\@/${postgress_host}/g' ${fetch_file}"    
    #-----

    #@@postgress_port@@ #Token in file...

    unset input
    read -p "Please Enter PostgreSQL port number [${postgress_port}]:> " input
    [ ! -z "${input}" ] && postgress_port=${input}
    printf "\nSetting Postgress Port: ${postgress_port} "
    eval "perl -p -i -e 's/\\@\\@postgress_port\\@\\@/${postgress_port}/g' ${fetch_file}"    
    [ $? == 0 ] && printf "[OK]\n" || printf "[FAIL]\n"

    printf "\Setting Postgress Log Dir: ${postgress_install_dir} "
    eval "perl -p -i -e 's#\\@\\@postgress_install_dir\\@\\@#${postgress_install_dir}#g' ${fetch_file}"    
    [ $? == 0 ] && printf "[OK]\n" || printf "[FAIL]\n"

    chown -R postgres.postgres ${postgress_install_dir}

    popd >& /dev/null
    echo
    check_shmmax
    echo
    write_postgress_env
    write_postgress_install_log
    checked_done 0
}

write_postgress_env() {
    ((show_summary_latch++))
    echo "export PGHOME=$PGHOME" >> ${envfile}
    echo "export PGUSER=$PGUSER" >> ${envfile}
    echo "export PGHOST=$PGHOST" >> ${envfile}
    echo "export PGPORT=$PGPORT" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_postgress_install_log() {
    echo "$(date ${date_format}) postgres=${postgress_version} ${postgress_install_dir}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}

start_postgress() {
    check_postgress_process && return 1
    
    echo "Starting Postgress..."
    echo "su $pg_sys_acct -c \"$postgress_install_dir/bin/pg_ctl -D $postgress_install_dir/data start\""
    su $pg_sys_acct -c "$postgress_install_dir/bin/pg_ctl -D $postgress_install_dir/data start"
    [ $? != 0 ] && echo " ERROR: Could not start database!" && popd && return 1

    #NOTE: How long does it take for the database to come up? Set sleep appropriately
    echo -n "Giving database time to startup... 3 seconds " 
    sleep 3
    /bin/ps -elf | grep postgres | grep -v grep
    checked_done 0
}

stop_postgress() {
    sleep 1
    #Stop the database
    #su postgres -c "pg_ctl -D /usr/local/pgsql/data stop" #(gently stop server) 
    #

    check_postgress_process 
    [ $? != 0 ] && return 1    

    echo 
    echo "stop postgress: su $pg_sys_acct -c \"pg_ctl -D $postgress_install_dir/data -m i stop\""
    su $pg_sys_acct -c "pg_ctl -D $postgress_install_dir/data -m i stop" #(stop server immediately)
    if [ $? != 0 ]; then
	echo " WARNING: Unable to stop the database (nicely)" 
	echo " Hmmm...  okay no more mr nice guy... issuing \"killall postgres\""
	killall postgres
	[ $? != 0 ] && echo "Hmmm... still could not shutdown... do so manually"
    fi
    /bin/ps -elf | grep postgres | grep -v grep
    return 0
}

test_postgress() {
    echo -n "Postgress Test...  "
    check_postgress_process 
    [ $? != 0 ] && echo "[FAILED] process not running..." && checked_done 1
    echo "(hit CTRL D to continue... if terminal is holding)"
    $postgress_install_dir/bin/psql -U $postgress_user ${pg_sys_acct}
    [ $? != 0 ] && printf "[FAILED]\n ERROR: $postgress_install_dir/bin/psql command failed" && checked_done 1
    checked_done 0
}

#####
# Python/CDMS
#####
setup_cdat() {
    echo
    echo "*******************************"
    echo "Setting up CDAT - (Python + CDMS)... ${cdat_version}"
    echo "*******************************"
    echo

    local dosetup
    if [ -x ${cdat_home}/bin/cdat ]; then 
	echo "Detected an existing CDAT installation..."
	read -p "Do you want to continue with CDAT installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping CDAT installation and setup - will assume CDAT is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null
    echo "This may take a few minutes... GIT over http is slooooow :-)"
    git clone ${cdat_repo}
    cd cdat >& /dev/null
    git checkout ${cdat_version} && \
	echo "pulling in cmor submodule" && \
	git submodule init && \
	git submodule update
    [ $? != 0 ] && echo " WARNING: Problem with cdat repository"

    echo "cleaning things out" 
    ./clean_script

    #NOTE: 
    #cdms configuration with --enable-esg flag looks for pg_config in
    #$postgress_install_dir/bin.  This location is created and added
    #to the executable PATH by the 'setup_postgress' function.
    
    echo "./configure --prefix=$cdat_home --enable-esg"
    ./configure --prefix=${cdat_home} --enable-esg   
    [ $? != 0 ] && echo " ERROR: Configure did not complete successfully" && popd && checked_done 1
    make
    [ $? != 0 ] && echo " ERROR: Could not compile (make) cdat code" && popd && checked_done 1

    ${cdat_home}/bin/python -c "import cdms2" 2>/dev/null
    [ $? != 0 ] && echo " ERROR: Could not load CDMS (cdms2) module" && popd && checked_done 1

    popd >& /dev/null    
    echo
    write_cdat_env
    write_cdat_install_log
    checked_done 0
}

write_cdat_env() {
    ((show_summary_latch++))
    echo "export CDAT_HOME=${cdat_home}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_cdat_install_log() {
    echo "$(date ${date_format}) cdat=${cdat_version} ${cdat_home}" >> ${install_logfile}
    
    #Parse the cdat installation config.log file and entries to the install log
    if [ -e ${workdir}/cdat/config.log ]; then
	awk '/building/ {print "'"$(date ${date_format})"' cdat:"$2"="$NF" <unknown>"}' ${workdir}/cdat/config.log >> ${install_logfile}
    else
	echo " WARNING: Could not find cdat config.log file [${workdir}/cdat/config.log] installation log entries could not be generated!"
    fi
    
    dedup ${install_logfile}
    return 0
}


#####
# ESGCET Package
#####
setup_esgcet() {
    echo
    echo "*******************************"
    echo "Setting up ESGCET Package..."
    echo "*******************************"
    echo

    local upgrade=${1:-0}    
    
    local dosetup
    if [ -e ${HOME}/.esgcet/esg.ini ]; then 
	echo "Detected an existing esgcet installation..."
	read -p "Do you want to continue with esgcet installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping esgcet installation and setup - will assume esgcet is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && return 1
    pushd ${workdir} >& /dev/null
    
    #Gives you 30 seconds to make a choice or will choose "I" by default
    local choice
    while [ 1 ]; do
	read -p "Is this an install or update of the esgcet module? [I/u]: " choice
	if [ "${choice}" = "i" ] || [ "${choice}" = "I" ] || [ -z "${choice}" ]; then
	    #echo "$cdat_home/bin/easy_install -f ${esg_dist_url}/externals esgcet"
	    #$cdat_home/bin/easy_install -f ${esg_dist_url}/externals esgcet
	    checked_get ${esg_dist_url}/externals/${esgcet_egg_file}
	    (( $? > 1 )) && return 0
	    $cdat_home/bin/easy_install ${esgcet_egg_file}
	    [ $? != 0 ] && checked_done 1
	elif [ "${choice}" = "u" ] || [ "${choice}" = "U" ]; then
	    #echo "$cdat_home/bin/easy_install --upgrade -f ${esg_dist_url}/externals esgcet"
	    #$cdat_home/bin/easy_install --upgrade -f ${esg_dist_url}/externals esgcet
	    checked_get ${esg_dist_url}/externals/${esgcet_egg_file}
	    (( $? > 1 )) && return 0
	    $cdat_home/bin/easy_install --upgrade ${esgcet_egg_file}
	    [ $? != 0 ] && checked_done 1
	else
	    echo "Not a valid selection..."
	    continue
	fi
	break
    done


    if((!upgrade)); then
	local input=""
	read -p "What is your organization's id? [${esg_root_id}]: " input
	[ ! -z "${input}" ] && esg_root_id=${input}
	
	echo "$cdat_home/bin/esgsetup --config --rootid ${esg_root_id}" 
	$cdat_home/bin/esgsetup --config --rootid ${esg_root_id}
	[ $? != 0 ] && popd && checked_done 1
    fi
    start_postgress

    echo "$cdat_home/bin/esgsetup --db"
    $cdat_home/bin/esgsetup --db
    [ $? != 0 ] && popd && checked_done 1

    popd >& /dev/null
    echo
    echo
    if((!upgrade)); then
	write_esgcet_env
    fi
    checked_done 0
}

write_esgcet_env() {
    echo "export ESG_ROOT_ID=$esg_root_id" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_esgcet_install_log() {
    echo "$(date ${date_format}) python:esgcet=${esgcet_version}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}


test_esgcet() {
    echo -n "ESGCET Test... "
    pushd $workdir >& /dev/null

    #esgcet_testdir=$(readlink -f ${thredds_root_dir})/test
    esgcet_testdir=${thredds_root_dir}/test
    mkdir -p ${esgcet_testdir}
    [ $? != 0 ] && checked_done 1
    mkdir -p ${thredds_replica_dir}
    [ $? != 0 ] && checked_done 1

    echo "esgcet test directory: [${esgcet_testdir}]"
    local fetch_file
    fetch_file=sftlf.nc
    checked_get ${esgcet_testdir}/${fetch_file} ${esg_dist_url}/externals/${fetch_file}
    (( $? > 1 )) && echo " ERROR: Problem pulling down ${fetch_file} from esg distribution" && popd && checked_done 1


    #Run test...
    echo "$cdat_home/bin/esginitialize -c "
    $cdat_home/bin/esginitialize -c 
    echo "$cdat_home/bin/esgscan_directory --dataset pcmdi.${esg_root_id}.test.mytest --project test ${esgcet_testdir} > mytest.txt"
    $cdat_home/bin/esgscan_directory --dataset pcmdi.${esg_root_id}.test.mytest --project test ${esgcet_testdir} > mytest.txt
    [ $? != 0 ] && echo " ERROR: ESG directory scan failed" && popd && checked_done 1
    
    echo "$cdat_home/bin/esgpublish --map mytest.txt --project test --model test"
    $cdat_home/bin/esgpublish --map mytest.txt --project test --model test
    [ $? != 0 ] && echo " ERROR: ESG publish failed" && popd && checked_done 1
    

    popd >& /dev/null
    echo
    echo
    checked_done 0
}

#####
# Apache Tomcat
#####
setup_tomcat() {
    echo
    echo "*******************************"
    echo "Setting up Apache Tomcat..."
    echo "*******************************"
    echo 

    local dosetup
    if [ -x ${tomcat_install_dir}/bin/jsvc ]; then 
	echo "Detected an existing tomcat installation..."
	read -p "Do you want to continue with tomcat installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping tomcat installation and setup - will assume tomcat is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null
    
    local tomcat_dist_file=${tomcat_dist_url##*/}
    #strip off .tar.gz at the end, i.e. last 7 chars, to get untarred dir name
    tomcat_dist_dir=$(echo ${tomcat_dist_file} | awk '{print substr($1,1,length($1)-7)}')

    #There is this pesky case of having a zero sized dist file... WTF!?                                                                            
    if [ -e ${tomcat_dist_file} ]; then
        ls -l ${tomcat_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${tomcat_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${tomcat_dist_file}
    fi

    #Check to see if we have a tomcat distribution directory
    if [ ! -e ${tomcat_install_dir%/*}/${tomcat_dist_dir} ]; then
	echo "Don't see tomcat distribution dir ${tomcat_install_dir%/*}/${tomcat_dist_dir}"
	if [ ! -e ${tomcat_dist_file} ]; then
	    echo "Don't see tomcat distribution file $(pwd)/${tomcat_dist_file} either"
	    echo "Downloading Tomcat from ${tomcat_dist_url}"
	    wget -O ${tomcat_dist_file} ${tomcat_dist_url}
	    [ $? != 0 ] && echo " ERROR: Could not download Tomcat" && popd && checked_done 1
    	    tar xvzf ${tomcat_dist_file} -C ${tomcat_install_dir%/*} # i.e. /usr/local
	    [ $? != 0 ] && echo " ERROR: Could not extract Tomcat" && popd && checked_done 1
	fi
    fi

    #If you don't see the directory but see the tar.gz distribution
    #then expand it
    if [ -e ${tomcat_dist_file} ] && [ ! -e ${tomcat_install_dir%/*}/${tomcat_dist_dir} ]; then
	tar xvzf ${tomcat_dist_file} -C ${tomcat_install_dir%/*} # i.e. /usr/local
	[ $? != 0 ] && echo " ERROR: Could not extract Tomcat..." && popd && checked_done 1
    fi

    if [ ! -e ${tomcat_install_dir} ]; then
	ln -s ${tomcat_install_dir%/*}/${tomcat_dist_dir} ${tomcat_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR: Could not create sym link ${tomcat_install_dir%/*}/${tomcat_dist_dir} -> ${tomcat_install_dir}" && popd && checked_done 1
    else
	unlink ${tomcat_install_dir}
	[ $? != 0 ] && mv ${tomcat_install_dir} ${tomcat_install_dir}.$(date ${date_format}).bak

	ln -s ${tomcat_install_dir%/*}/${tomcat_dist_dir} ${tomcat_install_dir}
	[ $? != 0 ] && \
	    echo " ERROR: Could not create sym link ${tomcat_install_dir%/*}/${tomcat_dist_dir} -> ${tomcat_install_dir}" && popd && checked_done 1
    fi
    
    #If there is no tomcat user on the system create one (double check that usradd does the right thing)
    id $tomcat_user
    if [ $? != 0 ]; then 
	echo " WARNING: There is no tomcat user \"$tomcat_user\" present on system"
	#NOTE: "useradd/groupadd" are a RedHat/CentOS thing... to make this cross distro compatible clean this up.
	/usr/sbin/groupadd -r -f ${tomcat_group}
	[ $? != 0 ] && echo "ERROR: Could not add tomcat system group: ${tomcat_group}" && popd && checked_done 1
	/usr/sbin/useradd -r -u91 -c"Tomcat Server Identity" -g $tomcat_group $tomcat_user
	[ $? != 0 ] && echo "ERROR: Could not add tomcat system account user \"$tomcat_user\"" && popd && checked_done 1
    fi
        

    cd $tomcat_install_dir

    #----------
    #build jsvc (if necessary)
    #----------
    echo -n "Checking for jsvc... "
    if [ -e ./bin/jsvc ] && [ -x ./bin/jsvc ]; then
	echo "[OK]"
    else
	echo "[BAD]"
	[ ! -x ./bin/jsvc ] &&  rm -v ./bin/jsvc >& /dev/null
	echo "Building jsvc... (JAVA_HOME=$java_install_dir)"
	cd bin
	[ -e ./jsvc-src ] && echo "removing source tree for jsvc" && rm -v -rf ./jsvc-src
	tar xvzf jsvc.tar.gz
	cd jsvc-src
	autoconf
	chmod 755 ./configure
	./configure --with-java=$java_install_dir
	make
	cp jsvc ..
	cd ../.. #(back up to tomcat_install_dir)
    fi
    #----------



    #----------------------------
    # TOMCAT Configuration...
    #----------------------------

    cd $tomcat_install_dir/conf
    
    local fetch_file

    fetch_file=server.xml
    checked_get ./${fetch_file} ${esg_dist_url}/externals/bootstrap/dnode.${fetch_file}
    (( $? > 1 )) && popd && checked_done 1
    chmod 600 ${fetch_file}

    #Create a keystore in $tomcat_install_dir/conf
    echo "Keystore setup: "
    if [ ! -e ${keystore_file} ]; then
	echo "Launching Java's keytool: we suggest using the default Tomcat password \"changeit\""
	#$JAVA_HOME/bin/keytool -list -keystore keystore-tomcat
	$java_install_dir/bin/keytool -genkey -alias ${keystore_alias} -keyalg RSA -keystore ${keystore_file} -validity 365
	[ $? != 0 ] && echo " ERROR: keytool command failed" && popd && checked_done 1
    else
	echo "Using existing keystore \"${keystore_file}\""
    fi

    #Fetch/Copy truststore to $tomcat_install_dir/conf
    #(first try getting it from distribution server otherwise copy Java's)
    if [ ! -e ${truststore_file} ]; then
	fetch_file=jssecacerts
	checked_get ${truststore_file} ${esg_dist_url}/externals/${fetch_file}
	if (( $? > 1 )); then
	    echo " Warning: Could not download certificates ${fetch_file} for tomcat - will copy local java certificat file"
	    echo "(note - the truststore password will probably not match!)"
	    cp -v ${java_home}/jre/lib/security/cacerts ${truststore_file}
	    [ $? != 0 ] && echo " ERROR: Could not fetch or copy ${fetch_file} for tomcat!!" && popd && checked_done 1
	fi
    fi
    
    #Edit the server.xml file to contain proper location of certificates
    eval "perl -p -i -e 's#\\@\\@truststore_file\\@\\@#${truststore_file}#g' server.xml"
    eval "perl -p -i -e 's#\\@\\@keystore_file\\@\\@#${keystore_file}#g' server.xml"


    chown -R $tomcat_user $(readlink -f ${tomcat_install_dir})
    [ $? != 0 ] && " ERROR: Could not change ownership of tomcat to \"$tomcat_user\" user" && popd && checked_done 1
    chgrp -R $tomcat_group $(readlink -f ${tomcat_install_dir})
    [ $? != 0 ] && " ERROR: Could not change group of tomcat to \"$tomcat_user\" user" && popd && checked_done 1
    
    start_tomcat

    echo "---------------------------------------------------------"
    echo "Should see the page source below: means server works :-)"
    echo "--------------------page source start--------------------"
    echo "curl http://localhost:80"
    curl http://localhost:80
    echo "--------------------page source end----------------------"
    echo
    
    popd >& /dev/null
    echo
    echo
    write_tomcat_env
    write_tomcat_install_log
    return 0
}

write_tomcat_env() {
    ((show_summary_latch++))
    echo "export CATALINA_HOME=${CATALINA_HOME}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_tomcat_install_log() {
    echo "$(date ${date_format}) tomcat=${tomcat_version} $(readlink -f ${tomcat_install_dir})" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}


start_tomcat() {
    check_tomcat_process && return 1

    echo "Starting Tomcat (jsvc)..."
    pushd $tomcat_install_dir >& /dev/null
    jsvc_launch_command="JAVA_HOME=$java_install_dir ./bin/jsvc -Djava.endorsed.dirs=./endorsed -pidfile $tomcat_pid_file -cp $(find $(readlink -f `pwd`/bin/) | grep jar | xargs | perl -pe 's/ /:/g') -outfile ./logs/catalina.out -errfile ./logs/catalina.err -user $tomcat_user $java_opts -Dsun.security.ssl.allowUnsafeRenegotiation=true org.apache.catalina.startup.Bootstrap"
    echo "$jsvc_launch_command"
    JAVA_HOME=$java_install_dir ./bin/jsvc -Djava.endorsed.dirs=./endorsed -pidfile $tomcat_pid_file \
	-cp $(find $(readlink -f `pwd`/bin/) | grep .jar | xargs | perl -pe 's/ /:/g') \
	-outfile ./logs/catalina.out \
	-errfile ./logs/catalina.err \
	-user $tomcat_user \
	$java_opts -Dsun.security.ssl.allowUnsafeRenegotiation=true \
	org.apache.catalina.startup.Bootstrap
    if [ $? != 0 ]; then 
	echo " ERROR: Could not start up tomcat"
	tail ./logs/catalina.err
	popd >& /dev/null
	checked_done 1
    fi
    
    #NOTE: How long does it take for tomcat to come up? Set sleep appropriately
    local wait_time=5
    echo -n "Giving tomcat time to startup... $wait_time seconds " 
    sleep $wait_time
    curl http://localhost:80 >& /dev/null
    [ $? != 0 ] && echo " WARNING: Could not verify tomcat is running..." || echo "[OK]"
    ps -elf | grep jsvc  | grep -v grep
    date
    popd >& /dev/null
    checked_done 0
}

stop_tomcat() {
    #
    #Stop Tomcat
    #% sudo /usr/local/tomcat/bin/jsvc -pidfile /var/run/tomcat-jsvc.pid -stop org.apache.catalina.startup.Boostrap
    #

    check_tomcat_process 
    [ $? != 0 ] && return 1

    pushd $tomcat_install_dir >& /dev/null
    echo 
    echo "stop tomcat: ./bin/jsvc -pidfile $tomcat_pid_file -stop org.apache.catalina.startup.Bootstrap"
    echo "(please wait)"
    sleep 1
    ./bin/jsvc -pidfile $tomcat_pid_file -stop org.apache.catalina.startup.Bootstrap
    if [ $? != 0 ]; then
	echo " WARNING: Unable to stop tomcat, (nicely)" 
	echo " Hmmm...  okay no more mr nice guy... issuing \"killall jsvc\" and \"pkill -9 $(cat ${tomcat_pid_file})\""
	killall jsvc
	kill -9 $(cat ${tomcat_pid_file}) >& /dev/null
	[ $? != 0 ] && echo "Hmmm... still could not shutdown... process may have already been stopped"
    fi
    /bin/ps -elf | grep jsvc | grep -v grep
    popd >& /dev/null
    return 0
}

test_tomcat() {

    echo -n "Tomcat Test...  "
    start_tomcat

    echo "---------------------------------------------------------"
    echo "Should see the page source below: means server works :-)"
    echo "--------------------page source start--------------------"
    echo "curl http://localhost:80"
    curl http://localhost:80
    local ret=$?
    echo "--------------------page source end----------------------"
    echo

    checked_done $?
}

#####
# Install The Data Node Manager
#####
# - Takes boolean arg: 0 = setup / install mode (default)
#                      1 = updated mode
#
# In setup mode it is an idempotent install (default)
# In update mode it will always pull down latest after archiving old
#
setup_node() {
    echo
    echo "*******************************"
    echo "Setting up The ESG Node Manager..."
    echo "*******************************"
    echo

    local upgrade=${1:-0}

    local dosetup
    if [ -d ${node_app_home} ]; then 
	echo "Detected an existing node manager installation..."
	read -p "Do you want to continue with node manager installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping node manager installation and setup - will assume it's setup properly"
	    return 0
	fi
	
	local dobackup="N"
	read -p "Do you want to make a back up of the existing distribution?? [y/N] " dobackup
	if [ "${dobackup}" = "Y" ] || [ "${dobackup}" = "y" ]; then
	    echo "Creating a backup archive of this web application $node_app_home"
	    backup ${node_app_home}
	fi

	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && return 1
    pushd ${workdir} >& /dev/null
    local fetch_file


    local node_dist_file=${node_dist_url##*/}
    #strip off .tar.gz at the end, i.e. last 7 chars, to get untarred dir name 
    #(Ex: esg-node.0.0.1.tar.gz -> esg-node.0.0.1)
    node_dist_dir=$(echo ${node_dist_file} | awk '{print substr($1,1,length($1)-7)}')

    checked_get ${node_dist_file} ${node_dist_url}
    no_new_update=$?

    if((upgrade)); then
	((no_new_update == 1)) && echo "nothing more to do, you are up2date" && return 1
	echo "Upgrading the ESG Node Manager..."
	if [ -e ${node_dist_dir} ]; then
	    local archive=${node_dist_dir}.arch.$(date ${date_format}).tgz
	    echo "...archiving... ${node_dist_dir} -> ${archive} ${node_dist_dir}"
	    tar czf ${archive} ${node_dist_dir}
	    echo "...removing... ${node_dist_dir}"
	    rm -rf ${node_dist_dir}
	fi
    fi
    
    tar xzf ${node_dist_file}
    [ $? != 0 ] && echo " ERROR: Could not extract the ESG Node: ${node_dist_file}" && popd && checked_done 1
    
    pushd ${node_dist_dir} >& /dev/null

    stop_tomcat

    #strip the version number off(.#.#.#) the dir and append .war to get the name of war file
    #(Ex: esg-node.0.0.1 -> esg-node.war)
    local trimmed_name=$(pwd)/$(echo ${node_dist_dir} | awk '{print substr($1,1,length($1)-6)}')
    node_war_file=${trimmed_name}.war
    echo "node_war_file = "${node_war_file}

    mkdir -p ${node_app_home}
    cd ${node_app_home}


    #----------------------------
    fetch_file=node.properties

    #NOTE: The saving of the last config file must be done *BEFORE* we untar the new distro!
    if ((upgrade)) && [ -e WEB-INF/classes/${fetch_file} ]; then
	cp WEB-INF/classes/${fetch_file} WEB-INF/classes/${fetch_file}.saved
	chmod 600 WEB-INF/classes/${fetch_file}*
    fi

    echo "Expanding war ${node_war_file} in $(pwd)"
    $JAVA_HOME/bin/jar xf ${node_war_file}
    
    
    #----------------------------
    #Property file fetching and token replacement...
    #----------------------------
    pushd WEB-INF/classes >& /dev/null

    cp ${fetch_file} ${fetch_file}.tmpl
    if((upgrade)) && [ -e ${fetch_file}.saved ]; then
	#reuse the last node.properties file...
	#pull it out of the tar archive we made a few lines up
	cp ${fetch_file}.saved ${fetch_file}
    else
        #----------------------
	pwd
	echo -n "Replacing tokens... "

	eval "perl -p -i -e 's/\\@db.driver\\@/${postgress_driver}/g' ${fetch_file}"    
	echo -n "*"
	eval "perl -p -i -e 's/\\@db.protocol\\@/${postgress_protocol}/g' ${fetch_file}"
	echo -n "*"
	
	eval "perl -p -i -e 's/\\@db.host\\@/${postgress_host}/g' ${fetch_file}"    
	echo -n "*"
	eval "perl -p -i -e 's/\\@db.port\\@/${postgress_port}/g' ${fetch_file}"
	echo -n "*"
	eval "perl -p -i -e 's/\\@db.database\\@/${node_db_name}/g' ${fetch_file}"
	echo -n "*"
	eval "perl -p -i -e 's/\\@db.user\\@/${postgress_user}/g' ${fetch_file}"
	echo -n "*"
	eval "perl -p -i -e 's/\\@db.password\\@/${pg_sys_acct_passwd}/g' ${fetch_file}"
	echo -n "*"
	
	eval "perl -p -i -e 's/\\@mail.smtp.host\\@/${mail_smtp_host}/g' ${fetch_file}"
	echo -n "*"
	eval "perl -p -i -e 's/\\@mail.admin.address\\@/${mail_admin_address}/g' ${fetch_file}"
	echo -n "*"
	echo " [OK]"
        #----------------------
    fi
    chown -R ${tomcat_user} ${node_app_home}
    chgrp -R ${tomcat_group} ${node_app_home}
    unset fetch_file
    popd >& /dev/null
    #----------------------------

    popd >& /dev/null
    (( ! upgrade )) && configure_postgress
    write_node_install_log
    checked_done 0

}

write_node_install_log() {
    echo "$(date ${date_format}) webapp:node_mgr=${node_version} ${node_app_home}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}


#--------------------------------------------------
#NOTE: This must be run AFTER the esg node web app
#      installation/configuration (setup_node) 
#--------------------------------------------------
configure_postgress() {
    
    echo
    echo "*******************************"
    echo "Configuring Postgres... (for Data Node Manager)"
    echo "*******************************"
    echo

    start_postgress

    #Create the database...
    echo "Creating esg node database: ${node_db_name}"
    echo "${postgress_install_dir}/bin/createdb ${node_db_name}"
    ${postgress_install_dir}/bin/createdb ${node_db_name} >& /dev/null
    (( $? > 1 )) && echo " ERROR: Could not create esg node database: ${node_db_name}" && return 0
        
    #TODO... Make the above call idempotent...
    #NOTE: (zoiks) Need to be able to tell the difference between a
    #database already there vs another error

    pushd ${workdir}/${node_dist_dir:-esg-node${node_version}}/db
    [ $? != 0 ] && echo " ERROR: Could not find node distribution dir ${workdir}/${node_dist_dir}" && checked_done 1

    echo "${ANT_HOME}/bin/ant -buildfile database-tasks.ant.xml \
	-Dnode.property.file=${node_app_home}/WEB-INF/classes/node.properties \
        -Dsql.jdbc.base.url=${postgress_protocol}//${postgress_host}:${postgress_port}/ \
        -Dsql.jdbc.database.name=${node_db_name} \
        -Dsql.jdbc.database.user=${postgress_user} \
        -Dsql.jdbc.database.password=${pg_sys_acct_passwd} \
        -Dsql.jdbc.driver.jar=${node_app_home}/WEB-INF/lib/${postgress_jar} make_node_db"

    ${ANT_HOME}/bin/ant -buildfile database-tasks.ant.xml \
	-Dnode.property.file=${node_app_home}/WEB-INF/classes/node.properties \
        -Dsql.jdbc.base.url=${postgress_protocol}//${postgress_host}:${postgress_port}/ \
        -Dsql.jdbc.database.name=${node_db_name} \
        -Dsql.jdbc.database.user=${postgress_user} \
        -Dsql.jdbc.database.password=${pg_sys_acct_passwd} \
        -Dsql.jdbc.driver.jar=${node_app_home}/WEB-INF/lib/${postgress_jar} make_node_db >& /dev/null
    (( $? > 1 )) && echo "ERROR: Could not create esg node database tables in ${node_db_name}" && return 1
    
    popd >& /dev/null
    echo
    echo
    checked_done 0
}

#####
# THREDDS Data Server
#####
setup_tds() {
    echo
    echo "*******************************"
    echo "Setting up Thredds Data Server..."
    echo "*******************************"
    echo

    local dosetup
    if [ -d ${tomcat_install_dir}/webapps/thredds ]; then 
	echo "Detected an existing thredds installation..."
	read -p "Do you want to continue with thredds installation and setup? [y/N] " dosetup
	if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
	    echo "Skipping thredds installation and setup - will assume thredds is setup properly"
	    return 0
	fi
	echo
    fi

    mkdir -p ${workdir}
    [ $? != 0 ] && return 1
    pushd ${workdir} >& /dev/null
    local fetch_file

    ############################
    #Download the thredds.war file home site (or use value of thredds_dist_file if already set)
    ############################

    thredds_dist_file=${thredds_dist_file:-${thredds_dist_url##*/}}
    
    #There is this pesky case of having a zero sized dist file... WTF!?                                                                            
    if [ -e ${thredds_dist_file} ]; then
        ls -l ${thredds_dist_file}
	#NOTE: I know there must be a cleaner way to get this, maybe stat?
        local size=$(ls -l | grep ${thredds_dist_file} | tr -s " " | cut -d " " -f 5)
        (( size == 0 )) && rm -v ${thredds_dist_file}
    fi

    #Check to see if we have this war file already in the workbench...
    #if [ ! -e ${thredds_dist_file} ]; then
    #	wget -O ${thredds_dist_file} ${thredds_dist_url}
    #	if [ $? != 0 ]; then
    #	    echo " ERROR: Could not download ${thredds_dist_url}, fetching the copy at PCMDI (LLNL)..."
    	    checked_get ${thredds_dist_file} ${thredds_esg_dist_url}
    	    (( $? > 1 )) && echo " ERROR: Could not download ${thredds_esg_dist_url} either" && popd && checked_done 1
    #	fi
    #fi
    
    stop_tomcat
    
    #-------------------------------------------
    #installing the thredds web app ("manually")
    cp ${thredds_dist_file} ${tomcat_install_dir}/webapps
    pushd ${tomcat_install_dir}/webapps
    mkdir thredds
    cd thredds
    jar xvf ../${thredds_dist_file}
    cd ..
    chown -R ${tomcat_user}  thredds*
    chgrp -R ${tomcat_group} thredds*
    rm ${thredds_dist_file}
    popd
    #-------------------------------------------


    ############################
    #Setup Digest authentication
    ############################

    pushd $tomcat_install_dir/conf/ >& /dev/null

    fetch_file=tomcat-users.xml
    checked_get $tomcat_install_dir/conf/${fetch_file} ${esg_dist_url}/externals/bootstrap/${fetch_file}
    (( $? > 1 )) && popd && checked_done 1
    chown ${tomcat_user}  $tomcat_install_dir/conf/${fetch_file}
    chgrp ${tomcat_group} $tomcat_install_dir/conf/${fetch_file}
    

    #1: Generate password hash
    printf "Create user credentials\n"
    local input

    while [ 1 ]; do 
	#default credential values...
	local username="dnode_user"
	local password="changeme"
	unset input
	unset addanother
	read -p "Please enter username for tomcat [${username}]:  " input
	[ ! -z "${input}" ] && username=${input}    
	echo ${username}
	unset input
	read -s -t60 -p "Please enter password for user, \"${username}\" [********]:   " input
	[ ! -z "${input}" ] && password=${input}    
	password_hash=$($tomcat_install_dir/bin/digest.sh -a SHA ${password} | cut -d ":" -f 2)
	echo ${password_hash}
	
	#Create user entry in tomcat-users.xml for thredds user
	user_entry="<user username=\"${username}\" password=\"${password_hash}\" roles=\"tdrAdmin,tdsConfig\"\/>"
	#Note: Have to escape the last "/" in "/>"
	
    	#Insert the entry in the right place in tomcat-users.xml
    	#Replace <!--@@user_entry@@--> with ${user_entry}\n<!--@@user_entry@@-->
	#Command Line:% perl -p -i -e 's/<!--\@\@user_entry\@\@-->/<test>\n  <!--\@\@user_entry\@\@-->/g' tomcat-users.xml
	eval "perl -p -i -e 's/<!--\\@\\@user_entry\\@\\@-->/${user_entry}\n  <!--\\@\\@user_entry\\@\\@-->/g' tomcat-users.xml"
	
	read -p "Would you like to add another user? [y/N]: " addanother
	if [ "${addanother}" = "y" ] || [ "${addanother}" = "Y" ]; then
	    echo 
	    continue
	fi
	echo
	break
    done
    unset input

    popd >& /dev/null

    ############################
    #Enable SSL encryption
    ############################

    mkdir -p ${tomcat_install_dir}/conf/Catalina/localhost
    fetch_file=thredds.xml
    checked_get $tomcat_install_dir/conf/Catalina/localhost/${fetch_file} ${esg_dist_url}/externals/bootstrap/tomcat-${fetch_file}
    (( $? > 1 )) && echo " ERROR: Problem pulling down ${fetch_file} from esg distribution" && popd && checked_done 1

    
    #Get the templated web.xml file... (with tokens for subsequent filter entries: see [esg-]security-[saml|token]-filters[.xml] files)
    fetch_file=web.xml 
    checked_get ${tomcat_install_dir}/webapps/thredds/WEB-INF/${fetch_file} ${esg_dist_url}/thredds/thredds.${fetch_file}
    (( $? > 1 )) && popd && checked_done 1
    chown -R ${tomcat_user}  ${tomcat_install_dir}/webapps/thredds/WEB-INF/${fetch_file} 
    chgrp -R ${tomcat_group} ${tomcat_install_dir}/webapps/thredds/WEB-INF/${fetch_file} 

    #DEBUGGING
    (($DEBUG)) && cat ${tomcat_install_dir}/webapps/thredds/WEB-INF/${fetch_file}


    #(Making this assignment for the sake of readability for the code below)
    #@@node_host_ip_address@@ #Token in file
    node_host_ip_address=${my_ip_address}    

    #just to be sure it's clear (though it should be)
    unset input 
    read -p "Please Enter the IP address of this host [${node_host_ip_address}]:> " input
    [ ! -z "${input}" ] && node_host_ip_address=${input}
    printf "\nUsing IP: ${node_host_ip_address}\n"
    unset input

    #@@gateway_name@@ -> @@gateway_service_root@@  #Tokens in file
    #ESG-PCMDI -> pcmdi3.llnl.gov/esgcet
    #ESC-NCAR  -> esg.prototype.ucar.edu
    
    local choice
    while [ 1 ]; do
	unset choice
	printf "Please select the gateway for this node: \n"
	printf "\t-------------------------------------------\n"
	printf "\t*[1] : ESG-PCMDI -> pcmdi3.llnl.gov/esgcet\n"
	printf "\t [2] : ESG-NCAR  -> esg.ucar.edu\n"
	printf "\t-------------------------------------------\n"
	printf "\t [C] : (Manual Entry)\n"
	printf "\t-------------------------------------------\n"
	read -p "select [1] > " choice
	
	[ -z "${choice}" ] && choice=1 #default
	case ${choice} in
	    2)  gateway_name="ESG-NCAR"
		gateway_service_root="esg.ucar.edu"
		;;
	    1)  gateway_name="ESG-PCMDI"
		gateway_service_root="pcmdi3.llnl.gov/esgcet"
		myproxy_port=2119 #hack till we open the right port
		;;
	    c | C)
		gateway_name=${ESG_GATEWAY_NAME:-"ESG-PCMDI"}
		gateway_service_root=${ESG_GATEWAY_SVC_ROOT:-"pcmdi3.llnl.gov/esgcet"}
		read -p "Please enter the Gateway name [${ESG_GATEWAY_NAME}] " gateway_name
		read -p "Please enter the Gateway Service Root [${ESG_GATEWAY_SVC_ROOT}] " gateway_service_root
		gateway_name=$(echo ${gateway_name} | tr 'a-z' 'A-Z')
		choice="(Manual Entry)"
		;;
	    *)  echo "Invalid selection [${choice}]"
	esac
	echo
	echo "You have selected: ${choice}"
	echo "${gateway_name} -> ${gateway_service_root}"
	echo 
	local is_correct
	read -p "Is this correct? [Y/n] " is_correct
	is_correct=$(echo ${is_correct} | tr 'A-Z' 'a-z')
	if [ "${is_correct}" = "n" ]; then
	    continue
	else
	    break
	fi
    done
    
    myproxy_endpoint=${gateway_service_root%%/*}

    echo
    echo "Selection: [${choice}] source: ${node_host_ip_address}   dest: ${gateway_name}:${gateway_service_root}"

    #----------------------
    #Fetch and Insert the Certificate for parent gateway
    register ${myproxy_endpoint}
    #----------------------

    #restart tomcat to put modifications in effect.
    stop_tomcat 
    start_tomcat
    start_postgress

    #set in cdms setup (prerequisite)
    $cdat_home/bin/esgsetup --thredds --publish --gateway ${myproxy_endpoint}

    popd >& /dev/null
    echo
    mkdir -p ${thredds_root_dir}
    [ $? != 0 ] && echo " Error: could not create ${thredds_root_dir}" && checked_done 1
    mkdir -p ${thredds_replica_dir}
    [ $? != 0 ] && echo " Error: could not create ${thredds_replica_dir}" && checked_done 1
    echo

    sleep 3
    echo "curl http://${node_host_ip_address}/thredds"
    curl http://${node_host_ip_address}/thredds
    [ $? != 0 ] && echo "[FAILED]" && echo " ERROR: Not able to contact thredds page on this server" && checked_done 1
    
    write_tds_env
    write_tds_install_log
    checked_done 0
}

write_tds_env() {
    ((show_summary_latch++))
    echo "export ESG_GATEWAY_NAME=${gateway_name}" >> ${envfile}
    echo "export ESG_GATEWAY_SVC_ROOT=${gateway_service_root}" >> ${envfile}
    echo "export myproxy_port=${myproxy_port}" >> ${envfile}
    dedup ${envfile}
    return 0
}

write_tds_install_log() {
    echo "$(date ${date_format}) webapp:tds=${tds_version} ${tomcat_install_dir}/webapps/${thredds_dist_file}" >> ${install_logfile}
    dedup ${install_logfile}
    return 0
}

test_tds() {
    echo -n "Thredds Data Server Test... "
    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null

    start_tomcat
    start_postgress

    echo "$cdat_home/bin/esgpublish --use-existing pcmdi.${esg_root_id}.test.mytest --noscan --thredds"
    $cdat_home/bin/esgpublish --use-existing pcmdi.${esg_root_id}.test.mytest --noscan --thredds
    [ $? != 0 ] && echo "[FAILED]" && echo " ERROR: Not able to run esgpublish command" && popd && checked_done 1
    sleep 2
    echo "curl http://${node_host_ip_address}/thredds"
    curl http://${node_host_ip_address}/thredds
    [ $? != 0 ] && echo "[FAILED]" && echo " ERROR: Not able to contact thredds page on this server" && popd && checked_done 1
    
    echo "[PASSED]"
    popd >& /dev/null
    echo
    echo
    checked_done 0
}






#####
# Globus Toolkit ->  MyProxy (client) & GridFTP (server)
#####
# Takes arg ["with-bdm-config"|"bdm-config-only"] see esg-globus script
setup_globus() {
    echo -n "Globus Setup for Data-Node... (GridFTP server)"
    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null

    pushd ${scripts_dir} >& /dev/null
    local fetch_file=esg-globus
    checked_get ./${fetch_file} ${esg_dist_url}/externals/bootstrap/${fetch_file}
    (( $? > 1 )) && popd && return 1
    chmod 755 ${fetch_file}
    popd >& /dev/null

    source ${scripts_dir}/${fetch_file} && setup_globus_services datanode $@
    local ret=$?
    popd >& /dev/null
    [ ${ret} = 0 ] && write_globus_env || checked_done 1
    touch ${globus_location}/esg_${progname}_installed
    checked_done 0
}

write_globus_env() {
    ((show_summary_latch++))
    echo "export GLOBUS_LOCATION=$GLOBUS_LOCATION" >> ${envfile}
    echo "export X509_CERT_DIR=$X509_CERT_DIR" >>  ${envfile}
    #echo "export gridftp_config_args=$gridftp_config_args" >> ${envfile}
    dedup ${envfile}
    return 0
}


#####
# Test Publication
#####

test_publication() {
    echo "Publication test..."
    [ -z "${myproxy_user}" ] && read -p "Enter your myproxy username: " myproxy_user

    local personal_credential_repo="$HOME/.globus"

    mkdir -p ${personal_credential_repo}

    [ "$(ls -A ${X509_CERT_DIR})" ] && echo "Detected existing content in \$X509_CERT_DIR" || rmdir ${X509_CERT_DIR}
    
    echo "X509_CERT_DIR = ${X509_CERT_DIR}"
    echo "$globus_location/bin/myproxy-logon -s $myproxy_endpoint -l $myproxy_user -p $myproxy_port -o ${personal_credential_repo}/certificate-file -T"
    $globus_location/bin/myproxy-logon -s $myproxy_endpoint -l $myproxy_user -p $myproxy_port -o ${personal_credential_repo}/certificate-file -T

    #(other) way...
    #rm -rf $X509_CERT_DIR
    #echo "$globus_location/bin/myproxy-get-trustroots -s $myproxy_endpoint"
    #$globus_location/bin/myproxy-get-trustroots -s $myproxy_endpoint

    [ $? != 0 ] && echo " ERROR: MyProxy not setup properly.  Unable to execute command." && return 1

    #Publish the dataset from the THREDDS catalog created above...
    echo "$cdat_home/bin/esgpublish --use-existing pcmdi.${esg_root_id}.test.mytest --noscan --publish"
    $cdat_home/bin/esgpublish --use-existing pcmdi.${esg_root_id}.test.mytest --noscan --publish
    [ $? != 0 ] && echo " ERROR: unable to successfully execute esgpublish" && return 1
    sleep 3

    echo "$cdat_home/bin/esgunpublish --skip-thredds pcmdi.${esg_root_id}.test.mytest"
    $cdat_home/bin/esgunpublish --skip-thredds pcmdi.${esg_root_id}.test.mytest
    [ $? != 0 ] && echo " ERROR: unable to successfully execute esgunpublish" && return 1

    return 0
}

#NOTE: Here we are enforcing a bit of a convention... The name of
#subsystem files must be in the form of esg-xxx-xxx where the script
#contains its "main" function named setup_xxx_xxx(). The string passed
#to this function is "xxx-xxx"
#
#arg (1) - name of installation script root name. Ex:security which resolves to script file esg-security
#arg (2) - [optional] directory on the distribution site where script is fetched from Ex: orp
#usage: setup_subsystem security orp - looks for the script esg-security in the distriubtion dir orp
setup_subsystem() {
    local subsystem=$1
    [ -z "${subsystem}" ] && echo "setup_subsystem [${subsystem}] requires argument!!" && checked_done 1
    local server_dir=${2:-"externals/bootstrap"}
    
    echo
    read -p "Would you like to set up ${subsystem} services? [Y/n] " dosetup
    if [ "${dosetup}" = "N" ] || [ "${dosetup}" = "n" ] || [ "${dosetup}" = "no" ]; then
	return 0
    fi    

    #if [ "${dosetup}" != "Y" ] && [ "${dosetup}" != "y" ]; then
    #	echo "Skipping ${subsysem} installation"
    #	return 0
    #fi
    echo

    echo -n "${subsystem} setup for Data-Node... "
    mkdir -p ${workdir}
    [ $? != 0 ] && checked_done 1
    pushd ${workdir} >& /dev/null

    pushd ${scripts_dir} # >& /dev/null
    local fetch_file=esg-${subsystem}
    checked_get ./${fetch_file} ${esg_dist_url}/${server_dir}/${fetch_file}
    (( $? > 1 )) && popd && return 1
    chmod 755 ${fetch_file}
    popd # >& /dev/null

    #source subsystem file and go!
    shift && echo "-->>> "
    shift && echo "-->>> "
    source ${scripts_dir}/${fetch_file} && echo ":-) " && setup_${subsystem//'-'/_} $@
    checked_done $?
}

#####
# Show user summary and environment variables that have been set
#####
show_summary() {
    if [ $((show_summary_latch == 0)) = 1 ]; then return 0; fi
    echo 
    echo "-------------------"
    echo "  $esg-node run summary: "
    echo "-------------------"
    echo "The following environment variables were used during last full install"
    echo "They are written to the file ${envfile}"
    echo "Please source this file when using these tools"
    echo 
    cat ${envfile}
    echo "-------------------"
    echo "Installation Log:"
    echo 
    cat ${install_logfile}
    echo "-------------------"
    echo 
    return 0
}

write_env() {
    echo "Generating default ${envfile} file"
    [ -e ${envfile} ] && cp ${envfile} ${envfile}.bak 
    cat /dev/null > ${envfile}
    write_paths
    write_git_env
    write_java_env
    write_ant_env
    write_postgress_env
    write_cdms_env
    write_esgcet_env
    write_tomcat_env
    write_tds_env
    write_globus_env
    echo "-------------------"
    cat ${envfile}
    echo "-------------------"
    return 0
}


############################################
# Utility Functions
############################################

#####
# This function is for pulling in keys from hosts we wish to
# communicate with over an encrypted ssl connection.  This function
# must be run after tomcat is set up since it references server.xml.
#####
#(called by setup_tds)
#arg1 - hostname of the machine with the cert you want to get
register() {
    echo "Installing Certificate From Gateway...( -> MyProxy endpoint)"
    
    local certfile=jssecacerts

    mkdir -p ${workdir} # >& /dev/null
    pushd ${workdir} # >& /dev/null
    #Download the Java code used for certificate installation (into $workdir)
    checked_get ${utils_url}/InstallCert.class
    (( $? > 1 )) && echo " ERROR: Could not download utility class(1) for installing certificates" && popd && return 1
    checked_get ${utils_url}/'InstallCert$SavingTrustManager.class'
    (( $? > 1 )) && echo " ERROR: Could not download utility class(2) for installing certificates" && popd && return 1
    popd # >& /dev/null

    pushd $tomcat_install_dir/conf >& /dev/null

    [ -e ${certfile} ] && cp ${certfile} ${certfile}.bak
    
    local input=${1:-${ESG_GATEWAY_SVC_ROOT%%/*}}
    local ssl_endpoint=${input%%/*} #just need the hostname
    local ssl_port=${ssl_port:-443}
    local ssl_endpoint_passwd=${2:-changeit}
    
    local CP=".:${workdir}"

    echo "${JAVA_HOME}/bin/java -classpath ${CP} InstallCert \
	${ssl_endpoint}:${ssl_port} ${ssl_endpoint_passwd}"
    ${JAVA_HOME}/bin/java -classpath ${CP} InstallCert \
	${ssl_endpoint}:${ssl_port} ${ssl_endpoint_passwd}
    local ret=$?

    #------
    local there=$(pwd)
    pushd ${JAVA_HOME}/jre/lib/security >& /dev/null
    [ -e ${certfile} ] && cp ${certfile} ${certfile}.bak
    cp ${there}/${certfile} ${certfile}
    chmod 644 ${certfile}
    popd >& /dev/null
    #------

    chmod 644 ${certfile}
    chown $tomcat_user ${certfile}
    chgrp $tomcat_group ${certfile}    
    popd >& /dev/null
    return $ret
}

#NOTE: This is another **RedHat/CentOS** specialty thing (sort of)
#arg1 - min value of shmmax in MB (see: /etc/sysctl.conf)
check_shmmax() {
    set_value_mb=${1:-40} #default is 32MB + headroom = 40MB
    let set_value_bytes=$((set_value_mb*1024*1024))
    cur_value_bytes=$(sysctl -q kernel.shmmax | tr -s "=" | cut -d= -f2)
    let cur_value_bytes=${cur_value_bytes## }
    
    if ((cur_value_bytes < set_value_bytes)); then
	echo "Current system shared mem value too low [$cur_value_bytes bytes] changing to [$set_value_bytes bytes]"
	sysctl -w kernel.shmmax=${set_value_bytes}
	echo "kernel.shmmax = ${set_value_bytes}" >> /etc/sysctl.conf
    fi
}

uninstall() {
    local doit="N"
    read -p "Are you sure you want to uninstall? [y/N]: " doit
    if [ "$doit" = "y" ] || [ "$doit" = "Y" ]; then

	doit="N"
	if [ -e $postgress_install_dir ]; then 
	    read -p "remove postgress? ($postgress_install_dir) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing $postgress_install_dir"
		rm -rf ${postgress_install_dir}
		[ $? != 0 ] && echo "ERROR: Unable to remove ${postgress_install_dir}"
	    fi
	fi
	
	doit="N"
	if [ -e $cdat_home ]; then
	    read -p "remove cdat? ($cdat_home) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing $cdat_home"
		rm -rf ${cdat_home}
		[ $? != 0 ] && echo "ERROR: Unable to remove ${cdat_home}"
	    fi
	fi

	doit="N"
	if [ -e ${HOME}/.esgcet ]; then
	    read -p "remove .esgcet files? (${HOME}/.esgcet) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing ${HOME}/.esgcet"
		rm -rf ${HOME}/.esgcet
		[ $? != 0 ] && echo "ERROR: Unable to remove ${HOME}/.esgcet}"
	    fi
	fi

	doit="N"
	if [ -e ${node_app_home} ]; then
	    read -p "remove ESG Node web service? (${tomcat_install_dir}/webapps/${node_app_context_root}) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing ${tomcat_install_dir}/webapps/${node_app_context_root}"
		rm -rf ${tomcat_install_dir}/webapps/${node_app_context_root}
		[ $? != 0 ] && echo "ERROR: Unable to remove ${tomcat_install_dir}/webapps/${node_app_context_root}"
	    fi
	fi 

	doit="N"
	if [ -e ${tomcat_install_dir}/webapps/thredds ]; then
	    read -p "remove Thredds web service? (${tomcat_install_dir}/webapps/thredds) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing ${tomcat_install_dir}/webapps/thredds"
		rm -rf ${tomcat_install_dir}/webapps/thredds
		[ $? != 0 ] && echo "ERROR: Unable to remove ${tomcat_install_dir}/webapps/thredds"
	    fi
	fi 

	doit="N"
	if [ -e $tomcat_install_dir ]; then
	    read -p "remove apache tomcat? ($tomcat_install_dir) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing $tomcat_install_dir"
		rm -ri $tomcat_install_dir
		[ $? != 0 ] && echo "ERROR: Unable to remove ${tomcat_install_dir}"
	    fi
	fi
	
	doit="N"
	if [ -e ${globus_location}/esg_${progname}_installed ] && (( ! no_globus )); then
	    read -p "remove globus certs? ($globus_location) [y/N]: " doit
	    if [ "doit" = "Y" ] || [ "$doit" = "y" ]; then
		echo "removing $globus_location"
		[ -n ${globus_location} ] && [ -e ${globus_location} ] && rm -rf ${globus_location}
		[ $? != 0 ] && echo "ERROR: Unable to remove ${globus_location}"
	    fi
	fi
    fi
    exit 0
}

set_classpath() {
    local CP="."
    CP=${CP}:${node_app_home}/WEB-INF/classes
    
    for i in $( ls ${node_app_home}/WEB-INF/lib ); do
	CP=${CP}:${node_app_home}/WEB-INF/lib/"$i"
    done
    
    CP=${CP}:${CATALINA_HOME}/lib/servlet-api.jar
    CLASSPATH=${CP}
    export CLASSPATH
    return 0;
}

#This function "succeeds" (is true)  if there *are* running processes found
check_postgress_process() {
    val=$(ps -elf | grep postgres | grep -v grep | awk ' END { print NR }')
    [ $(($val > 0 )) == 1 ] && echo "Postgres process is running..." && return 0
    return 1
}

#This function "succeeds" (is true)  if there *are* running processes found
check_tomcat_process() {
    val=$(ps -elf | grep jsvc | grep -v grep | awk ' END { print NR }')
    [ $(($val > 0 )) == 1 ] && echo "Tomcat (jsvc) process is running..." && return 0
    return 1
}

#-----
#(A quick and dirty function for checking version)
#returns okay (0) if the current version is newer than specified target version
#-----
check_version() {
    [ -z $2 ] && return 0
    ((DEBUG)) && echo $2
    local target_version=$(echo $2 | perl -ne '/(\d+.*\d*.*\d*[_.]*\d*).*/, print "$1 "' | tr -d "." | tr -d "_" | tr -d "\"" | cut -d " " -f1,1)
    ((DEBUG)) && echo "target_version = [$target_version]"
    $1 --version >& /tmp/f || $1 -version >& /tmp/f
    [ $? != 0 ] && echo && echo "Oops, $1 command not found" && return 2
    line=($(cat /tmp/f 2>&1 | perl -ne '/(\d+.*\d*.*\d*[_.]*\d*).*/, print "$1 "' | tr -d "." | tr -d "_" | tr -d "\"" | cut -d " " -f1,1))
    
    #-----
    #If you are reading this... I know this looks a bit hokey...
    #But I could not find an easy way (in bash) to post-pend 0's to a string.
    #(no printf doesn't do that, sadly)
    #This will take care of the case where you want to make sure that someone with 
    #java version 1.6.0_20 is not considered higher than someone with 1.7
    #since 16020 is indeed "greater than" 17 vs
    #16020 being properly compared to 17000 :-)
    #I could have sub-shelled out to perl or python to do this in a call but where possible, 
    #I like to stay in bash.  If you know of a better/cleaner solution feel free to make it happen.
    #(yes... I know you could just pass in 17000) but then that doesn't parse against the regex
    #so to keep version number formats consistent... this is cleanest.)
    let i=0

    while (( ${#target_version} < ${#line} )); do
	target_version=$((target_version*10))
	((i == 6)) && exit
	((i++))
    done
    #-----

    ((DEBUG)) && echo "[$line] >= [$target_version] ?"
    [ $((line >= $target_version)) == 1 ] && return 0
    echo "Minimum Target version: $2 is newer than..."
    cat /tmp/f
    rm /tmp/f >& /dev/null
    return 1
}

checked_done() {
    if (($1)); then
	echo ""
	echo "Sorry..."
	echo "This action did not complete successfully"
	echo "Please re-run this task until successful before continuing further"
	echo ""
	exit 1
    fi
    return 0
}

# Does an md5 check between local and remote resource
# returns 0 (success) iff there is no match and thus indicating that
# an update is available.
# USAGE: checked_for_update [file] http://www.foo.com/file
#
check_for_update() {
    local local_file
    local remote_file
    if (( $# == 1 )); then
        remote_file=${1}
        local_file=$(readlink -f ${1##*/})
    elif (( $# == 2 )); then
        local_file=${1}
        remote_file=${2}
    else
        echo "function \"checked_for_update\":  Called with incorrect number of args! (fatal)"
        exit 1
    fi                      
    
    [ ! -e ${local_file} ] && echo " WARNING: Could not find local file ${local_file}" && return 0
    [ ! -x ${local_file} ] && echo " WARNING: local file ${local_file} not executible" && chmod 755 ${local_file}
    diff <(md5sum ${local_file} | tr -s " " | cut -d " " -f 1) <(curl ${remote_file}.md5 | tr -s " " | cut -d " " -f 1) >& /dev/null
    [ $? != 0 ] && echo " Update Available @ ${remote_file}" && return 0
    echo " ==> ${local_file} is up to date"
    return 1
}

# If an update is available then pull it down... then check the md5 sums again!
#
#  Yes, this results in 3 network calls to pull down a file, but it
#  saves total bandwidth and it also allows the updating from the
#  network process to be cronttab-able while parsimonious with
#  resources.  It is also very good practice to make sure that code
#  being executed is the RIGHT code!
#
# NOTE: Has multiple return values test for (( $? > 1 )) when looking or errors
#       A return value fo 1 only means that the file is up-to-date and there
#       Is no reason to fetch it.
#
# USAGE: checked_get [file] http://www.foo.com/file
#
checked_get() {
    check_for_update $@
    [ $? != 0 ] && return 1

    local local_file
    local remote_file
    if (( $# == 1 )); then
        remote_file=${1}
        local_file=${1##*/}
    elif (( $# == 2 )); then
        local_file=${1}
        remote_file=${2}
    else
        echo "function \"checked_get\":  Called with incorrect number of args! (fatal)"
        exit 1
    fi                      
    
    if [ -e ${local_file} ]; then
	cp -v ${local_file} ${local_file}.bak 
	chmod 600 ${local_file}.bak
    fi
    wget -O ${local_file} ${remote_file}
    [ $? != 0 ] && echo " ERROR: Problem pulling down [${remote_file##*/}] from esg distribution site" && return 2
    diff <(md5sum ${local_file} | tr -s " " | cut -d " " -f 1) <(curl ${remote_file}.md5 | tr -s " " | cut -d " " -f 1) >& /dev/null
    [ $? != 0 ] && echo " WARNING: Could not verify this file!" && return 3
    echo "[VERIFIED]"
    return 0
}

#arg1 - a filesystem path
backup() {
    [ -z "$1" ] && echo "backup - source must be provided as arg1" && return 1
    local source="$(readlink -f $1)"
    echo "Backup - Creating a backup archive of ${source}"
    pushd ${source%/*} >& /dev/null
    mkdir -p ${backupdir} >& /dev/null
    local backup_filename=$(readlink -f ${backupdir})/${source##*/}.$(date ${date_format}).tgz
    tar czf ${backup_filename} ${source##*/}
    [ $? != 0 ] && echo " ERROR: Problem with creating backup archive: ${backup_filename}" && popd >& /dev/null && return 1
    if [ -e ${backup_filename} ]; then 
	echo "Created backup: ${backup_filename}" 
    else
	echo "Could not locate backup file ${backup_filename}"
	popd >& /dev/null
	return 1
    fi
    

    #-------------
    #keep only the last num_backups_to_keep files
    num_backups_to_keep=${num_backups_to_keep:-7}
    pushd ${backupdir} >& /dev/null
    files=(`ls -t | grep ${source##*/}.\*.tgz | tail -n +$((${num_backups_to_keep}+1)) | xargs`)
    if (( ${#files[@]} > 0 )); then
	echo "Tidying up a bit..."
	echo "${#files[@]} old backup files to remove: ${files[@]}"
	rm -v ${files[@]}
    fi
    popd >& /dev/null
    #-------------

    popd >& /dev/null
    return 0

    
}

backup_db() {
    mkdir -p ${backupdir}
    pushd ${backupdir} >& /dev/null
    
    echo -n "Backing up database: ${node_db_name} to  ${node_db_name}_backup_$(date ${date_format}).sql"
    pg_dump -U ${postgress_user} ${node_db_name} > ${node_db_name}_backup_$(date ${date_format}).sql
    [ $? == 0 ] && echo " [OK] " || echo " [FAIL] "
    echo -n "Backing up security schema to ${node_db_name}_security_backup_$(date ${date_format}).sql"
    pg_dump -U ${postgress_user} --schema security ${node_db_name} > ${node_db_name}_security_backup_$(date ${date_format}).sql
    [ $? == 0 ] && echo " [OK] " || echo " [FAIL] "
    
    popd >& /dev/null
    return 0
}

#Replace a pattern inside the target file with the contents of the input file
insert_file_at_pattern() {
    local target_file=$1
    local input_file=$2
    local pattern=$3

    echo "Inserting into ${target_file} <- ${input_file} at pattern ${pattern}"

    python -c "infile = '${target_file}';filterfile = '${input_file}';pattern='${pattern}';f=open(infile);s=f.read();f.close();f=open(filterfile);filter = f.read();f.close();s=s.replace(pattern,filter);f=open(infile,'w');f.write(s);f.close()"
    ret=$?
    [ $ret != 0 ] && echo "Problem in function insert_file_at_pattern in $0"
    return ${ret}
}

# Environment variable files of the form
# Ex: export FOOBAR=some_value
# Will have duplcate keys removed such that the
# last entry of that variable is the only one present
# in the final output.
# arg 1 - The environment file to dedup.
dedup() {
    local infile=${1:-${envfile}}
    local outfile=${infile}

    local key=""
    local last_key=""
    local value=""
    local last_value=""
    local output
    local i
    local dups
    
    let dups=0
    let i=0
    
    #What is key here is that we make sure the sort is a "stable" sort! (-t)
    for line in $(cat ${infile} | tr -s " " | cut -d " " -f2 | sort -s -t= -k1,1); do
	key=${line%=*}
	value=${line#*=}
	#echo "key is: [${key}]  value is: [${value}]"
	if [ "${key}" != "${last_key}" ]; then
		output[((i++))]="export ${last_key}=${last_value}"
	else
	    ((dups++))
	fi
	[ -n $key ] && last_key=$key
	last_value=$value
    done
    #boundary condition catch...
    output[((i++))]="export ${last_key}=${last_value}"

    ((dups == 0)) && unset output && return 0
    (($DEBUG)) && echo "Elided [${dups}] duplcate entries"
    
    i=0
    cat /dev/null > ${outfile}
    for entry in "${output[@]}"; do
	((i>0)) && echo $entry >> ${outfile}
	((i++))
    done
    (($DEBUG)) && echo "Deduped $(readlink -f ${infile})"
    return 0
}

#"private" function
_verify() {
    echo "diff <(md5sum ${0} | tr -s " " | cut -d " " -f 1) <(curl ${1}/esg-node/${0##*/}.md5 | tr -s " " | cut -d " " -f 1) >& /dev/null "
    diff <(md5sum ${0} | tr -s " " | cut -d " " -f 1) <(curl ${1}/esg-node/${0##*/}.md5 | tr -s " " | cut -d " " -f 1) >& /dev/null
    [ $? != 0 ] && return 3
    echo "[VERIFIED]"
    return 0
}

self_verify() {
    _verify 'http://rainbow.llnl.gov/dist' >& /dev/null 
    if (( $? == 3 )); then 
	printf "WARNING: $0 could not be verified!! \n(This file, ${0}, may have been tampered with or there is a newer version posted at the distribution server.\nPlease update this script.)\n\n"
	local choice="u"
	read -t $((1*60)) -p "Do you wish to Update and exit [u], continue anyway [c] or simply exit [N]? [u/c/N]: " choice
	if [ "$choice" = "C" ] || [ "$choice" = "c" ]; then
	    echo 
	    return 0
	elif [ "$choice" = "U" ] || [ "$choice" = "u" ]; then
	    echo "Updating local script with script from distribution server..."
	    /usr/local/bin/esg-update node
	    echo "Please re-run this updated script $0"
	    echo
	    exit 1
	else
	    echo
	    exit 1
	fi
    else
	return 0
    fi
    return 0
}

show_svc_list() {
    echo
    echo "---------------------------"
    echo "Running Node Services..."
    echo "---------------------------"
    lsof -i |egrep  'postgres|jsvc|globus-gr'
    echo "---------------------------"
    echo
}

#Starts the esg node
start() {
    init
    echo "starting services with globus using config: ${gridftp_config_args}"
    source ${scripts_dir}/esg-globus >& /dev/null && \
	start_globus_services datanode ${gridftp_config_args}
    start_postgress
    start_tomcat
    show_svc_list
}

#Stops the esg node
stop() {
    init
    stop_tomcat 
    stop_postgress 
    source ${scripts_dir}/esg-globus >& /dev/null && \
	stop_globus_services datanode ${gridftp_config_args}
    show_svc_list
}

############################################
# Main
############################################
info() {

    printf " 

    The goal of this script is to automate as many tasks as
    possible regarding the installation of the software stack that is
    the Data Node.  A software stack is a collection of tools that
    work in concert to perform a particular task or set of tasks that
    are semantically united.  Essentially, the gestalt is the ESG
    DataNode. The software stack is comprised of; Tomcat, Thredds,
    CDAT & CDMS, PostgreSQL, MyProxy and RedHat/CentOS. Through the
    installation process there are different accounts that are created
    that facilitate the communication between these separate software
    entities.  These credentials are internal to the stack.  It is
    recommended that you use the defaults provided throughout this
    installation.  The security impact with regards to the visibility
    and accessibility of the constituent components of the stack
    depends on other factors to be addressed by your organization.
    (It is for this reason why it would be advantageous to install on
    a virtual machine and manage security from a system wide level.:-)

    Please be sure that you have gotten your Gateway (my proxy)
    credentials from: 

    http://pcmdi3.llnl.gov/esgcet/home.htm -> \"create account\"

    This is required for publication.

    Data Node:
		   --------- 
		  |Tomcat   |
		  |-Node Mgr|
		  |-Thredds |
		  |-ORP     |
		  |---------|
		  |CDAT/CDMS|
		  |---------|
		  |Postgres |
		  |---------|
		  | MyProxy |  <===(HTTPS)===> [Gateway(s)]*
		  |---------|
		  | GridFTP |  <=============> [End User(s)]*
		  >---------<
		  | CentOS  |
		  |(Virtual)|
		  | Machine |	
		  |---------|        
		   ---------        

    -ESG \n\n" | more 
    
}

usage() {
    printf "
    usage:
     (as root)
     ${progname} ([--<directive>] | [start] | [stop] | [status] [restart]
        --prefix      - specify the top level directory for this entire installation
                        (default:/usr/local - currently:$install_prefix)
        --workdir     - specify the directory used by the installation to download and build esg artifacts for installation
                        (default:~/workbench/esg - currently:$workdir)
        --install     - goes through the installation process
                         will automatically start up data node services
        --verify      - runs the test code to verify installation
        --write-env   - writes the necessary env vars to file ${envfile}
        --version     - indicates the version of this script
        --check       - checks if this script is the most up-to-date posted
        --clear       - removes the file holding the enironment state of last install
        --clear-certs - removes the prescribed certificate directory used with myproxy
        --test-pub    - performs the publication test directly (same publication called in last step of install)
        --info        - provides a brief explaination of the DataNode
        --register    - connects to desired gateway, fetches and stores their certificate to enable SSL connection
        --upgrade     - upgrades the node manager
        --no-globus   - will not install any globus tools (for those with existing globus setups)
        --griftp-config - [ with-bdm-config | bdm-config-only ] without this arg uses default end-user config

        start   - start the data node's services
        stop    - stops the data node's services
        status  - status on data node's services
        restart - restarts the data node's services (calls stop then start :-/)
            (notice, no \"--\" to make rc friendly also chkconfig-able ;-)

    
      \"stop\" | \"start\" | \"status\"are meant to be run independent of other flags
      \"--install\" may be used with \"--verify\" but niether are not intended for use
      with stop or start or status
      Ex:
         ${progname} --install OR
         ${progname} --verify OR
         ${progname} --install --verify  OR
         ${progname} --write-env OR
         ${progname} --version OR
         ${progname} --clear OR
         ${progname} --test-pub OR
         ${progname} --info OR
         ${progname} --register [gateway.host.address] ([truststore passwd])
         ${progname} --gridftp-config [ with-bdm-config | bdm-config-only ]
         ${progname} stop  OR
         ${progname} start OR
         ${progname} status OR
    
      NOTE:
      *You must be root to run this program, sudo will not allow the use of needed
      *environment variables!!!! if you must use sudo do so only to become root proper
      *then source your user's .[bash]rc file so that root has it's envronment set accordingly!
      *After a full install there will be a file created ($envfile) that has the environment
      *vars that were used and set during the installation - this should be sourced by users
      *of this application stack.
    " | more
    exit 0
}

done_remark() {
    echo ""
    echo "Finished!..."
    echo "In order to see if this data node has been installed properly you may direct your browser to:"
    echo "http://${my_ip_address}/${node_app_context_root}"
    echo "http://${my_ip_address}/thredds"
    echo "http://${my_ip_address}/OpenidRelyingParty"
    echo 
    echo "To see the published test, go your specified gateway: [${ESG_GATEWAY_NAME}]"
    echo "http://${ESG_GATEWAY_SVC_ROOT}"
    echo "and browse to \"Test Project\" -> pcmdi.${esg_root_id}.test.mytest"
    echo ""
}

main() {
    let sel=0
    while [ -n "$1" ]; do
    #echo "arg ${i} = $1"
	local unshift=0
	case $1 in
	    --install | -i)
		(($DEBUG)) && echo "INSTALL SERVICES"
		let sel+=1
		;;
	    --verify | --test)
		#echo "VERIFY SERVICES"
		let sel+=2
		;;
	    start | --start)
		(($DEBUG)) && echo "START SERVICES"
		start
		exit 0
		;;
	    stop | --stop)
		(($DEBUG)) && echo "STOP SERVICES"
		stop
		exit 0
		;;
	    restart)
		stop
		sleep 2
		start
		exit 0
		;;
	    --write-env)
		let sel+=16
		echo
		;;
	    --version)
		echo ""
		echo "Version: $version"
		echo "Earth Systems Grid"
		echo "Data Node Installation Script"
		echo "Lawrence Livermore National Laboratory"
		echo ""
		exit 0
		;;
	    --clear)
		if [ -e ${envfile} ]; then 
		    mv -v ${envfile} ${envfile}.bak 
		    echo "Cleared envfile ${envfile}"
		fi
		exit 0
		;;
	    --clear-certs)
		init
		echo "Clearing out certs..."
		local cert_dir=${HOME}/.globus/certificates-esg
		[ -e ${cert_dir} ] && rm -rf ${cert_dir}
		exit 0
		;;
	    --test-pub)
		init
		echo "test_publication" && test_publication
		exit
		;;
	    --info)
		info
		exit
		;;
	    --upgrade | --update)
		self_verify
		init
		check_prerequisites
		[ $? != 0 ] && echo && exit 1
		
		#---------------
		#version checking...
		#---------------
		setup_curl
		setup_git
		setup_java
		setup_ant
		setup_postgress

		#The arg "1" indicates an upgrade (see functions)
		setup_esgcet 1
		setup_node 1

		echo "starting services with globus using config: ${gridftp_config_args}"
		source ${scripts_dir}/esg-globus >& /dev/null && \
		    start_globus_services datanode ${gridftp_config_args}
		start_postgress
		start_tomcat
		exit 0
		;;
	    --check)
		self_verify && echo "$0 is up-to-date"
		exit $?
		;;
	    --uninstall)
		init
		uninstall
		exit
		;;
	    --register)
		init
		#First arg is the server
		#Second arg is the password (not required)
		shift
		register $1 $2
		exit
		;;
	    --prefix)
		local pvalue
		shift
		until [ $(echo $1 | egrep '^\s*--') ] || [ -z "$1" ] || [ "$1" = "stop" ] || [ "$1" = "start" ] || [ "$1" = "status" ] || [ "$1" = "restart" ]; do
		    pvalue="$1"
		    (($DEBUG)) && echo "prefix value is: $1"
		    shift
		done
		unshift=1
		install_prefix=${pvalue}
		[ -z "${pvalue}" ] && printf "\nERROR: Did not properly set --prefix value!!!\n\n" && exit 1
		;;
	    --workdir)
		local wvalue
		shift
		until [ $(echo $1 | egrep '^\s*--') ] || [ -z "$1" ] || [ "$1" = "stop" ] || [ "$1" = "start" ] || [ "$1" = "status" ] || [ "$1" = "restart" ]; do
		    wvalue="$1"
		    (($DEBUG)) && echo "workdir value is: $1"
		    shift
		done
		unshift=1
		workdir=${wvalue}
		[ -z "${wvalue}" ] && printf "\nERROR: Did not properly set --workdir value!!!\n\n" && exit 1
		;;
	    --no-globus)
		no_globus=1
		;;
	    --gridftp-config)
		#acceptable args:  "with-bdm-config" | "bdm-config-only"
		#Gather up tokens after this switch as long as the
		#subsequent tokens do not start with "--"
		local tmpargs #array to store args for this switch.
		local let index=0
		shift
		until [ $(echo $1 | egrep '^\s*--') ] || [ -z "$1" ] || [ "$1" = "stop" ] || [ "$1" = "start" ] || [ "$1" = "status" ] || [ "$1" = "restart" ]; do
		    tmpargs[((index++))]=$1
		    (($DEBUG)) && echo "added $1 to args list: ${tmpargs[@]}"
		    shift
		done
		unshift=1
		[ "${#tmpargs}" = 0 ] && printf "\n\n must follow --gridftp-config with proper flag! \n\n" && usage
		gridftp_config_args=${tmpargs[@]}
		unset tmpargs
		;;
	    status | --status)
		#TODO conditionally reflect the status of globus (gridftp) process
		if check_postgress_process && check_tomcat_process; then
		    echo "Node Running..."
		else
		    echo "Stopped: No running processes detected"
		fi
		show_svc_list
		exit 0
		;;
	    -h | --help)
		usage
		;;
	    *)
		printf "\n ERROR: unknown switch $1 \n\n" && exit 1
		;;
	esac
	((!unshift)) && shift
    done

    self_verify

    (($DEBUG)) && echo "SEL = $sel"
    [ $((sel)) == 0 ] && usage

    echo
    echo "-----------------------------------"
    echo "ESG Data Node Installation Program"
    echo "-----------------------------------"
    echo 

    info

    local doit="n"
    read -p "Are you ready to begin the installation? [Y/n] " doit
    if [ "${doit}" = "N" ] || [ "${doit}" = "n" ] || [ "${doit}" = "no" ]; then
	exit 0
    fi    

    init
    check_prerequisites
    [ $? != 0 ] && echo && exit 1

    #---------------------------------------
    #Installation of basic system components.
    # (Only when one setup in the sequence is okay can we move to the next)
    #---------------------------------------
    [ $((sel & 1)) != 0 ] && setup_curl
    [ $((sel & 1)) != 0 ] && setup_git
    [ $((sel & 1)) != 0 ] && setup_java
    [ $((sel & 1)) != 0 ] && setup_ant
    [ $((sel & 1)) != 0 ] && setup_postgress
    [ $((sel & 2)) != 0 ] && test_postgress 
    [ $((sel & 1)) != 0 ] && setup_cdat 
    [ $((sel & 1)) != 0 ] && setup_esgcet 
    [ $((sel & 2)) != 0 ] && test_esgcet 
    [ $((sel & 1)) != 0 ] && setup_tomcat 
    [ $((sel & 2)) != 0 ] && sleep 5 && test_tomcat
    [ $((sel & 1)) != 0 ] && setup_tds 
    [ $((sel & 2)) != 0 ] && test_tds 
    [ $((sel & 1)) != 0 ] && setup_node #(tomcat off)

    #---------------------------------------
    #Installation of "plugin" subsystems... & filters
    #---------------------------------------
    #---filters------
    [ $((sel & 1)) != 0 ] && echo "security filters subsystem (TOKEN)" && setup_subsystem security-token-filters filters $@
    #[ $((sel & 1)) != 0 ] && echo "security filters subsystem (SAML)"  && setup_subsystem security-saml-filters filters $@
    #---subsystems--- 
    #[ $((sel & 1)) != 0 ] && echo "security orp subsystem" && setup_subsystem security orp $@
    #[ $((sel & 1)) != 0 ] && echo "product server subsystem" && setup_subsystem product-server $@


    #---------------------------------------
    # Globus Installation...
    #---------------------------------------
    [ $((sel & 1)) != 0 ] && (( ! no_globus )) && echo "setup_globus" && setup_globus ${gridftp_config_args}
    [ $((sel & 2)) != 0 ] && (( ! no_globus )) && echo "test_globus" && source ${scripts_dir}/esg-globus >& /dev/null \
    	&& test_globus_services datanode


    #---------------------------------------
    # Publishing Test...
    #---------------------------------------
    [ $((sel & 2)) != 0 ] && echo "test_publication" && test_publication 


    #---------------------------------------
    #Summary and Installation Housekeeping...
    #---------------------------------------
    [ $((sel & 1)) != 0 ] && echo "show_summary" && show_summary 
    [ $((sel & 16)) != 0 ] && echo "write_env" && write_env && exit 0
    

    #---------------------------------------
    #System Launch...
    #---------------------------------------
    (( ! no_globus )) && start_globus_services datanode ${gridftp_config_args}
    start_postgress
    start_tomcat
    
    echo
    show_svc_list
    echo
    done_remark
    echo 
    exit 0
}

#Set system traps
#trap stop_postgress INT TERM
#trap stop_tomcat INT TERM
#trap - INT TERM

echo "start time: `date`" >> ${logfile}
main $@
echo "end time: `date`" >> ${logfile}
exit 0
